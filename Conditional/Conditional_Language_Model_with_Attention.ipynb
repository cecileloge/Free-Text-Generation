{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS230 // Conditional Language Model with Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-XuY71GfoOlL",
        "mzVUh3ugx4-7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Conditional Language Model with Attention (5.1)\n",
        "\n",
        "\n",
        "*   STEP 1 TOKENIZE THE DATA\n",
        "*   STEP 2 PREPROCESS INTO SMALLER SEQUENCES FOR TRAINING\n",
        "*   STEP 3 TRAIN ATTENTION MODEL - WITH CONDITION\n",
        "*   STEP 4 EVALUATE RESULTS (BLEU & UNIVERSAL COSINE SIMILARITY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "b8941cd8-c398-4620-a3f0-1956295e4e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP 0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Dot, Permute\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply, Flatten, BatchNormalization, Add\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgJUkSeVz3Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "train = pd.read_csv('/content/drive/My Drive/CS230/finaldata_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/CS230/finaldata_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8ZuOz2VzcK",
        "outputId": "d984eb9d-2dc1-42df-f186-edd6133c5627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "data.head(5).iloc[:, :3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['animation', 'comedy', 'family']</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
              "      <td>Toy Story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['adventure', 'fantasy', 'family']</td>\n",
              "      <td>When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.</td>\n",
              "      <td>Jumanji</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['romance', 'comedy']</td>\n",
              "      <td>A family wedding reignites the ancient feud between next-door neighbors and fishing buddies John and Max. Meanwhile, a sultry Italian divorc√©e opens a restaurant at the local bait shop, alarming the locals who worry she'll scare the fish away. But she's less interested in seafood than she is in cooking up a hot time with Max.</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['comedy']</td>\n",
              "      <td>Just when George Banks has recovered from his daughter's wedding, he receives the news that she's pregnant ... and that George's wife, Nina, is expecting too. He was planning on selling their home, but that's a plan that -- like George -- will have to change with the arrival of both a grandchild and a kid of his own.</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a top-notch crew on various insane heists throughout Los Angeles while a mentally unstable detective, Vincent Hanna pursues him without rest. Each man recognizes and respects the ability and the dedication of the other even though they are aware their cat-and-mouse game may end in violence.</td>\n",
              "      <td>Heat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     genres  ...                        title\n",
              "0  ['animation', 'comedy', 'family']         ...  Toy Story                  \n",
              "1  ['adventure', 'fantasy', 'family']        ...  Jumanji                    \n",
              "2  ['romance', 'comedy']                     ...  Grumpier Old Men           \n",
              "3  ['comedy']                                ...  Father of the Bride Part II\n",
              "4  ['action', 'crime', 'drama', 'thriller']  ...  Heat                       \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIbez-9WM-l",
        "outputId": "d5325099-556e-4be8-bbbd-66a2447bdaa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "data['length'].plot(kind='hist', alpha=0.7, color='orange')\n",
        "plt.title('Histogram Snippet Length')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Average Snippet is: ', int(np.mean(data.length)), ' words.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average Snippet is:  48  words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBM529kn9pG"
      },
      "source": [
        "## STEP1 // LET'S TOKENIZE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7zJQEuHZGH"
      },
      "source": [
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]\n",
        "train['overview_stop']=['<START> '+a+' <END>' for a in train.overview_stop]\n",
        "test['overview_stop']=['<START> '+a+' <END>' for a in test.overview_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhzJv7vfoD1"
      },
      "source": [
        "# Tokenizing / Create a Tokenizer object\n",
        "\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 10000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "seqtokens = tokenizer.texts_to_sequences(liststrings)\n",
        "traintokens = tokenizer.texts_to_sequences(list(train.overview_stop))\n",
        "testtokens = tokenizer.texts_to_sequences(list(test.overview_stop))\n",
        "\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5g55F2yXtw"
      },
      "source": [
        "tokenizer.sequences_to_texts(seqtokens)[:5] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL58tZAufQPo"
      },
      "source": [
        "sequnk = [[1 if x ==1 else 0 for x in s] for s in seqtokens]\n",
        "count_unk = [np.sum(x) for x in sequnk]\n",
        "freq_unk = [float(np.sum(x)/len(x)) for x in sequnk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMy_odgfdaS",
        "outputId": "afec8c37-0fe4-4ffe-bf94-04e9231945a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "print('Average Number of <UNK>s is: ', np.round(np.mean(count_unk),1))\n",
        "print('Max Number of <UNK>s is: ', np.round(np.max(count_unk),1))\n",
        "\n",
        "print('Average Freq of <UNK>s is: ', np.round(np.mean(freq_unk),3))\n",
        "print('Max Freq of <UNK>s is: ', np.round(np.max(freq_unk),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Number of <UNK>s is:  2.4\n",
            "Max Number of <UNK>s is:  12\n",
            "Average Freq of <UNK>s is:  0.041\n",
            "Max Freq of <UNK>s is:  0.121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLC-Jkfo2ed0"
      },
      "source": [
        "lengths = [len(x) for x in seqtokens]\n",
        "maxlen = max(lengths)\n",
        "m = len(seqtokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ij5wJTE0zOn"
      },
      "source": [
        "x = pad_sequences(seqtokens, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDzX1yyo3add"
      },
      "source": [
        "y = np.array(data[['drama','comedy','thriller','romance','adventure','family']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLiH0nc03yAX",
        "outputId": "956f9e84-f880-40e6-950c-1a66db627e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"x shape: \", x.shape)\n",
        "print(\"y shape: \", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape:  (20691, 136)\n",
            "y shape:  (20691, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGL83TyZMtE"
      },
      "source": [
        "dict_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzVUh3ugx4-7"
      },
      "source": [
        "##STEP2 // PRE-PROCESS INTO SMALLER SEQUENCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6SrsXzYoe68",
        "outputId": "c6babdcc-d1b3-4ed1-a162-8484821372df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# PREPPING THE (INPUT GENRE) DATA:\n",
        "\n",
        "genredata = np.array(data[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretrain = np.array(train[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretest = np.array(test[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "\n",
        "m = genretrain.shape[0]\n",
        "num_genres = genretrain.shape[1]\n",
        "print(\"Size of Training Set: \", m) \n",
        "print(\"Max sequence length for input (genres):\", num_genres) #num_encoder_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Training Set:  20277\n",
            "Max sequence length for input (genres): 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wgKn6LrZ5mP",
        "outputId": "fa235e94-bc4d-43ec-d8f2-80874d6e31a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### WORD-LEVEL LANGUAGE MODEL WITH A FIXED WINDOW ###\n",
        "# Script inspired in parts by the CHAR-LEVEL model: lstm_text_generation.py by fchollet https://github.com/keras-team/keras\n",
        "# Adapted by: ceciloge@stanford.edu\n",
        "\n",
        "# Preprocess the text into smaller sequences of words on one side (window length), and output next word on the other\n",
        "win_len = 10\n",
        "tokens = traintokens\n",
        "genre_cond = [] #GENRE\n",
        "x_input = [] #INPUT\n",
        "y_next = []  #OUTPUT\n",
        "\n",
        "for j, text in enumerate(tokens):\n",
        "  if j%5000 == 0: print(\"We're at...\", j)\n",
        "  for i in range(len(text)-win_len):\n",
        "    x_input.append(text[i:i+win_len])\n",
        "    y_next.append(text[i+win_len])\n",
        "    genre_cond.append(genretrain[j,:])\n",
        "\n",
        "print(\"Total number of smaller sequences: \", len(x_input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're at... 0\n",
            "We're at... 5000\n",
            "We're at... 10000\n",
            "We're at... 15000\n",
            "We're at... 20000\n",
            "Total number of smaller sequences:  878744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqk-mv792NzP",
        "outputId": "00cceee4-b131-4581-b0cc-d7cb2015ae5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turning our sequences into arrays\n",
        "x_input_array = np.array([np.array(s) for s in x_input]) #Decoder Input\n",
        "y_next_array = np.array([np.array(s) for s in y_next])-1 #Decoder Output\n",
        "genre_array = np.array(genre_cond) #Encoder Input\n",
        "print('x Shape: ',x_input_array.shape)\n",
        "print('y Shape: ',y_next_array.shape)\n",
        "print('genre Shape: ',genre_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Shape:  (878744, 10)\n",
            "y Shape:  (878744,)\n",
            "genre Shape:  (878744, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_73CJ7MZ6k5"
      },
      "source": [
        "##STEP3 // TRAIN ATTENTION MODEL WITH CONDITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txulTMWD4XG1",
        "outputId": "c47f537b-8d0b-4196-81e2-86a2bf9a35b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### RNN LANGUAGE MODEL / WITH ATTENTION & CONDITION ###\n",
        "# By: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "h1 = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Two GRU Layers\n",
        "h2 = GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal')(h1)\n",
        "h3 = GRU(256, name = 'GRU2', return_sequences= True, kernel_initializer = 'glorot_normal')(h2)\n",
        "\n",
        "# Concatenate both GRU Layer Outputs\n",
        "h4 = Concatenate()([h1,h2,h3])\n",
        "\n",
        "# Attention done in several steps\n",
        "a = Dense(1, use_bias=False, activation='linear')(h4)\n",
        "a = Permute((2, 1))(a)\n",
        "a = Flatten()(a)\n",
        "a = Activation('softmax')(a)\n",
        "h = Dot(axes = [1,1])([a,h3])\n",
        "\n",
        "# Genre Input\n",
        "genre_input = Input(shape=(num_genres,))\n",
        "g = Dense(4, activation = 'relu', kernel_initializer = 'he_normal')(genre_input)\n",
        "# Concatenate\n",
        "h = Concatenate()([h,g])\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1', kernel_initializer = 'he_normal')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2', kernel_initializer = 'he_normal')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "gen_model = Model([ genre_input,seq_input], next_word)\n",
        "gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "miniseq (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 64)       640064      miniseq[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "GRU1 (GRU)                      (None, 10, 256)      247296      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "GRU2 (GRU)                      (None, 10, 256)      394752      GRU1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10, 576)      0           embedding[0][0]                  \n",
            "                                                                 GRU1[0][0]                       \n",
            "                                                                 GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10, 1)        576         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 1, 10)        0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 10)           0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 256)          0           activation[0][0]                 \n",
            "                                                                 GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            84          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 260)          0           dot[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          133632      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 2560)         1313280     dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "final (Dense)                   (None, 10000)        25610000    dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 28,339,684\n",
            "Trainable params: 28,339,684\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBy8VJxo8VMP",
        "outputId": "10822cbf-f42e-4ddc-d297-3f10120cfc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Optimizer, Loss & Compiling\n",
        "opt = Adamax(learning_rate=0.0004)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "gen_model.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg2ayY64NgpU",
        "outputId": "d8b3270d-6ac4-41f6-80f5-091dbed2e5f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model.load_weights('/content/drive/My Drive/CS230/Models/condatt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf41321080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycqkPSz1zPI",
        "outputId": "493dee5e-ed5e-4da1-cc67-f23ca7e057c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's train!\n",
        "gen_model.fit([genre_array, x_input_array], y_next_array,\n",
        "             batch_size = 256,\n",
        "             epochs = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3433/3433 [==============================] - 104s 30ms/step - loss: 1.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feced775518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlnXFSUQYzZx"
      },
      "source": [
        "gen_model.save_weights('/content/drive/My Drive/CS230/Models/condatt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO5_nAI1wmj"
      },
      "source": [
        "# Let's choose several seeds:\n",
        "string_seed0 = 'alex and max meet at school and discover a'\n",
        "string_seed1 = 'yesterday alex and max found out that'\n",
        "string_seed2 = 'professor andrew goes on a mission to' \n",
        "string_seed3 = 'alex is pretty rich and famous but she discovers'\n",
        "string_seed4 = 'judy is feeling sick and'\n",
        "string_seed5 = 'a group of friends decides to go out for'\n",
        "every = 5\n",
        "end = tokenizer.texts_to_sequences([['<end>']])[0][0] \n",
        "start = tokenizer.texts_to_sequences([['<start>']])[0][0] \n",
        "dicke = tokenizer.texts_to_sequences([[\"dickens'\"]])[0][0]\n",
        "\n",
        "# Functions to produce text with our Model\n",
        "# Sampling\n",
        "def sample(preds, greedy = False):\n",
        "  # This first function samples the next word based on the output logits from the model\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "  samp = np.random.multinomial(1, preds, 1)\n",
        "  if greedy: \n",
        "    out = max(1, np.argmax(preds))\n",
        "  else: \n",
        "    out = np.argmax(samp)\n",
        "  return out+1\n",
        "\n",
        "# Genre Utils\n",
        "listgenre = ['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy','foreign', \n",
        "             'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi','thriller', 'tv_movie', 'war', 'western']\n",
        "dictgenre = {listgenre[i] : i for i in range(len(listgenre))}\n",
        "\n",
        "# Generate Text\n",
        "def model_generate_text(model = gen_model, seed = string_seed1, genre = ['drama'], length = 100, greedy = False, verbose = True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "    genre_in = np.zeros((1,20))\n",
        "    for g in genre:\n",
        "      i = dictgenre[g]\n",
        "      genre_in[:,i] = 1\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    v = 0\n",
        "    while i != end and count <length:     \n",
        "      preds = model.predict([genre_in, x_in], verbose=0)[0]\n",
        "      i = sample(preds, greedy=greedy)\n",
        "      x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "      output.append(i)\n",
        "      count +=1\n",
        "      #v = count/15\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY6UGYmm5kb5",
        "outputId": "6f302cf5-70bf-4e93-a6ae-dd5663b0e5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model: \n",
        "\n",
        "seed1 = string_seed1\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(seed = seed1, genre =['fantasy'], length = 65)\n",
        "text3, output3 = model_generate_text(seed = seed1, genre =['mystery'], length = 65)\n",
        "text4, output4 = model_generate_text(seed = seed1, genre =['thriller', 'action'], length = 65)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "yesterday alex and max found out that rick accidentally happens to be his best friend . scott tries to find a way to free the reward but when his old nemesis idol goes from mild to new town to witness in a kidnapping chase . when the detective adopts the beautiful woman he believes he was committed to the smuggling robbers with the help of a veteran reporter . <end>\n",
            "yesterday alex and max found out that execute a nazi world who may or may not be the only hope is she will be able to make herself back in the state without musical and has to face even reaching . <end>\n",
            "yesterday alex and max found out that public belief discussing aspects of his curse . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQT8wd2SQzo"
      },
      "source": [
        "## STEP 4 // EVALUATE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPZWpwlTeF1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "univ_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-osxCTZy_L"
      },
      "source": [
        "# EVALUATE BLEU & COSINE SIMILARITY ON THE TEST SET\n",
        "\n",
        "def cosine_sim(x,y):\n",
        "    num = np.sum(x*y)\n",
        "    den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
        "    return num/float(den)\n",
        "\n",
        "# Generate Text for the evaluation process\n",
        "def eval_generate(seed, genre, length):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = seed\n",
        "    output = []\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "    genre_in = genre\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    v = 0\n",
        "    while count <length:     \n",
        "      preds = gen_model.predict([genre_in, x_in], verbose=0)[0]\n",
        "      i = sample(preds, greedy=True)\n",
        "      x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "      output.append(i)\n",
        "      count +=1\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output\n",
        "\n",
        "def evaluate_gen(greedy = True):\n",
        "  bleu = []\n",
        "  sim = [] \n",
        "\n",
        "  for j, synopsis in enumerate(testtokens):\n",
        "    #From test set:\n",
        "    input = tokenizer.sequences_to_texts([synopsis[:10]])[0]\n",
        "    output_test = synopsis[10:]\n",
        "    output_test_string = tokenizer.sequences_to_texts([output_test])[0]\n",
        "    output_test_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output_test]\n",
        "    emb_test = univ_embed([output_test_string])\n",
        "    l = len(synopsis)-10\n",
        "\n",
        "\n",
        "    #From model:\n",
        "    _, output = eval_generate(genre = genretest[j,:].reshape(1,20) ,seed = input, length = l)\n",
        "    output_string = tokenizer.sequences_to_texts([output])[0]\n",
        "    output_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output]\n",
        "    emb = univ_embed([output_string])\n",
        "    #Similarity Scores:\n",
        "    b = sentence_bleu([output_test_list], output_list, smoothing_function=SmoothingFunction().method2)\n",
        "    s = cosine_sim(emb, emb_test)\n",
        "\n",
        "    if j%100 == 0: \n",
        "      print(j, \" done!\")\n",
        "      #print(\"bleu: \", b)\n",
        "      #print(\"sim: \", s)\n",
        "\n",
        "    bleu.append(b)\n",
        "    sim.append(s)\n",
        "  \n",
        "  bleu_score = np.mean(bleu)\n",
        "  sim_score = np.mean(sim)\n",
        "  print(\"BLEU: \", bleu_score)\n",
        "  print(\"COS. SIMILARITY: \", sim_score)\n",
        "  return bleu_score, sim_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TsBUNBiHPc_",
        "outputId": "02ca835f-2a91-4ee5-96b4-48703517671b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"RNN Cond. Attention Performance:\")\n",
        "bleu_score_RNN, sim_score_RNN = evaluate_gen()\n",
        "\n",
        "print(\"----------- RNN Cond. Attention Performance -----------\")\n",
        "print(\"BLEU: \", np.round(bleu_score_RNN,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score_RNN,4))\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN Cond. Attention Performance:\n",
            "0  done!\n",
            "100  done!\n",
            "200  done!\n",
            "300  done!\n",
            "400  done!\n",
            "BLEU:  0.06874064140027232\n",
            "COS. SIMILARITY:  0.2573781403069859\n",
            "----------- RNN Cond. Attention Performance -----------\n",
            "BLEU:  0.0687\n",
            "COS. SIMILARITY:  0.2574\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
