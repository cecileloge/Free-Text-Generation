{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS230 // Unconditional Language Models (2/2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-XuY71GfoOlL",
        "mzVUh3ugx4-7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Unconditional Language Models (4.1bis & 4.2)\n",
        "\n",
        "\n",
        "*   STEP 1 TOKENIZE THE DATA\n",
        "*   STEP 2 PREPROCESS INTO SMALLER SEQUENCES FOR TRAINING\n",
        "*   STEP 3 TRAIN BIDIRECTIONAL GRU RNN TO PRODUCE TEXT\n",
        "*   STEP 4 TRAIN CONCATENATED GRU RNN WITH ATTENTION\n",
        "*   STEP 5 EVALUATE RESULTS (BLEU & UNIVERSAL COSINE SIMILARITY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "71281835-32e2-4f61-ecf1-a29920638e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP 0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Dot, Permute\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply, Flatten, BatchNormalization, Add\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgJUkSeVz3Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "train = pd.read_csv('/content/drive/My Drive/CS230/finaldata_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/CS230/finaldata_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8ZuOz2VzcK",
        "outputId": "250b3b7f-1f91-44df-c71d-e0d35e7b77c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "data.head(5).iloc[:, :3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['animation', 'comedy', 'family']</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
              "      <td>Toy Story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['adventure', 'fantasy', 'family']</td>\n",
              "      <td>When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.</td>\n",
              "      <td>Jumanji</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['romance', 'comedy']</td>\n",
              "      <td>A family wedding reignites the ancient feud between next-door neighbors and fishing buddies John and Max. Meanwhile, a sultry Italian divorc√©e opens a restaurant at the local bait shop, alarming the locals who worry she'll scare the fish away. But she's less interested in seafood than she is in cooking up a hot time with Max.</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['comedy']</td>\n",
              "      <td>Just when George Banks has recovered from his daughter's wedding, he receives the news that she's pregnant ... and that George's wife, Nina, is expecting too. He was planning on selling their home, but that's a plan that -- like George -- will have to change with the arrival of both a grandchild and a kid of his own.</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a top-notch crew on various insane heists throughout Los Angeles while a mentally unstable detective, Vincent Hanna pursues him without rest. Each man recognizes and respects the ability and the dedication of the other even though they are aware their cat-and-mouse game may end in violence.</td>\n",
              "      <td>Heat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     genres  ...                        title\n",
              "0  ['animation', 'comedy', 'family']         ...  Toy Story                  \n",
              "1  ['adventure', 'fantasy', 'family']        ...  Jumanji                    \n",
              "2  ['romance', 'comedy']                     ...  Grumpier Old Men           \n",
              "3  ['comedy']                                ...  Father of the Bride Part II\n",
              "4  ['action', 'crime', 'drama', 'thriller']  ...  Heat                       \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIbez-9WM-l",
        "outputId": "c2188370-7cdf-4757-986a-888a1ceb3772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "data['length'].plot(kind='hist', alpha=0.7, color='orange')\n",
        "plt.title('Histogram Snippet Length')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Average Snippet is: ', int(np.mean(data.length)), ' words.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average Snippet is:  48  words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBM529kn9pG"
      },
      "source": [
        "## STEP1 // LET'S TOKENIZE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7zJQEuHZGH"
      },
      "source": [
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]\n",
        "train['overview_stop']=['<START> '+a+' <END>' for a in train.overview_stop]\n",
        "test['overview_stop']=['<START> '+a+' <END>' for a in test.overview_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhzJv7vfoD1"
      },
      "source": [
        "# Tokenizing / Create a Tokenizer object\n",
        "\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 10000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "seqtokens = tokenizer.texts_to_sequences(liststrings)\n",
        "traintokens = tokenizer.texts_to_sequences(list(train.overview_stop))\n",
        "testtokens = tokenizer.texts_to_sequences(list(test.overview_stop))\n",
        "\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5g55F2yXtw"
      },
      "source": [
        "tokenizer.sequences_to_texts(seqtokens)[:5] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL58tZAufQPo"
      },
      "source": [
        "sequnk = [[1 if x ==1 else 0 for x in s] for s in seqtokens]\n",
        "count_unk = [np.sum(x) for x in sequnk]\n",
        "freq_unk = [float(np.sum(x)/len(x)) for x in sequnk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMy_odgfdaS",
        "outputId": "c9bb05fe-bed3-4afd-f511-6c9c86a82420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "print('Average Number of <UNK>s is: ', np.round(np.mean(count_unk),1))\n",
        "print('Max Number of <UNK>s is: ', np.round(np.max(count_unk),1))\n",
        "\n",
        "print('Average Freq of <UNK>s is: ', np.round(np.mean(freq_unk),3))\n",
        "print('Max Freq of <UNK>s is: ', np.round(np.max(freq_unk),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Number of <UNK>s is:  2.4\n",
            "Max Number of <UNK>s is:  12\n",
            "Average Freq of <UNK>s is:  0.041\n",
            "Max Freq of <UNK>s is:  0.121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLC-Jkfo2ed0"
      },
      "source": [
        "lengths = [len(x) for x in seqtokens]\n",
        "maxlen = max(lengths)\n",
        "m = len(seqtokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ij5wJTE0zOn"
      },
      "source": [
        "x = pad_sequences(seqtokens, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDzX1yyo3add"
      },
      "source": [
        "y = np.array(data[['drama','comedy','thriller','romance','adventure','family']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLiH0nc03yAX",
        "outputId": "5dbe98b1-4123-47d4-e018-c8b659b15443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"x shape: \", x.shape)\n",
        "print(\"y shape: \", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape:  (20691, 136)\n",
            "y shape:  (20691, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGL83TyZMtE"
      },
      "source": [
        "dict_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzVUh3ugx4-7"
      },
      "source": [
        "##STEP2 // PRE-PROCESS INTO SMALLER SEQUENCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wgKn6LrZ5mP",
        "outputId": "cb99abee-eb5e-43b3-b8ad-baf2aa3bc1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### WORD-LEVEL LANGUAGE MODEL WITH A FIXED WINDOW ###\n",
        "# Script inspired in parts by the CHAR-LEVEL model: lstm_text_generation.py by fchollet https://github.com/keras-team/keras\n",
        "# Adapted by: ceciloge@stanford.edu\n",
        "\n",
        "# Preprocess the text into smaller sequences of words on one side (window length), and output next word on the other\n",
        "win_len = 10\n",
        "#tokens = list(compress(seqtokens, drama_filter))\n",
        "tokens = traintokens\n",
        "x_rnn = []\n",
        "y_rnn = []\n",
        "\n",
        "for j, text in enumerate(tokens):\n",
        "  if j%5000 == 0: print(\"We're at...\", j)\n",
        "  for i in range(len(text)-win_len):\n",
        "    x_rnn.append(text[i:i+win_len])\n",
        "    y_rnn.append(text[i+win_len])\n",
        "\n",
        "print(\"Total number of smaller sequences: \", len(x_rnn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're at... 0\n",
            "We're at... 5000\n",
            "We're at... 10000\n",
            "We're at... 15000\n",
            "We're at... 20000\n",
            "Total number of smaller sequences:  878744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqk-mv792NzP",
        "outputId": "904a385a-4830-4e92-d4cc-f2f87c515d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turning our sequences into arrays\n",
        "x_rnn_array = np.array([np.array(s) for s in x_rnn])\n",
        "y_rnn_array = np.array([np.array(s) for s in y_rnn])-1\n",
        "print('x Shape: ',x_rnn_array.shape)\n",
        "print('y Shape: ',y_rnn_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Shape:  (878744, 10)\n",
            "y Shape:  (878744,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_73CJ7MZ6k5"
      },
      "source": [
        "##STEP3 // TRAIN BIDIRECTIONAL GRU RNN TO PRODUCE TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txulTMWD4XG1",
        "outputId": "c38330d5-7c99-479a-eabd-feffdb295bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### RNN LANGUAGE MODEL / NOW BIDIRECTIONAL ###\n",
        "# By: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Two BIDIRECTIONAL GRU Layers\n",
        "h = Bidirectional (GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal'))(h)\n",
        "h = Bidirectional (GRU(256, name = 'GRU2', kernel_initializer = 'glorot_normal'))(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "gen_model = Model(inputs = seq_input, outputs = next_word)\n",
        "gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "miniseq (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 10, 64)            640064    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 512)           494592    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1182720   \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 2560)              1313280   \n",
            "_________________________________________________________________\n",
            "final (Dense)                (None, 10000)             25610000  \n",
            "=================================================================\n",
            "Total params: 29,503,312\n",
            "Trainable params: 29,503,312\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO5_nAI1wmj"
      },
      "source": [
        "# Functions to produce text with our RNN model\n",
        "\n",
        "every = 5\n",
        "end = tokenizer.texts_to_sequences([['<end>']])[0][0] \n",
        "start = tokenizer.texts_to_sequences([['<start>']])[0][0] \n",
        "dicke = tokenizer.texts_to_sequences([[\"dickens'\"]])[0][0]\n",
        "\n",
        "def sample(preds, greedy = False):\n",
        "  # This first function samples the next word based on the output logits from the model\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "  samp = np.random.multinomial(1, preds, 1)\n",
        "  if greedy: \n",
        "    out = max(1, np.argmax(preds))\n",
        "  else: \n",
        "    out = np.argmax(samp)\n",
        "  return out+1\n",
        "\n",
        "def generate_text(epoch, _):\n",
        "  # This second function prints generated text at end of every few epochs\n",
        "  if epoch%every == 0:\n",
        "    print()\n",
        "    input = '<start> when siblings judy and peter discover a board game'\n",
        "    print('Seed: \"' + input + '\"')\n",
        "    output = []\n",
        "    x_in = np.array(tokenizer.texts_to_sequences([input])[0])\n",
        "    i = -1\n",
        "    count = 0\n",
        "    while i != end and count < 35:     \n",
        "      preds = gen_model.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      i = sample(preds)\n",
        "      x_in = np.append(x_in[1:],i)\n",
        "      output.append(i)\n",
        "      count+=1\n",
        "      \n",
        "    print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "\n",
        "# Defining our callbacks:\n",
        "checkpoint = ModelCheckpoint(filepath='model',\n",
        "                             frequency = \"epoch\",\n",
        "                             save_weights_only = True,\n",
        "                             verbose = 0)\n",
        "\n",
        "gen_callback = LambdaCallback(on_epoch_end=generate_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBy8VJxo8VMP",
        "outputId": "65477964-401e-43a7-f0da-5d6938187e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Optimizer, Loss & Compiling\n",
        "opt = Adamax(learning_rate=0.001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "gen_model.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg2ayY64NgpU",
        "outputId": "facc8732-c12e-487f-9dfa-a34c85c9f07f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model.load_weights('/content/drive/My Drive/CS230/Models/bidirectional')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f574cdca710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycqkPSz1zPI",
        "outputId": "02a191b2-3be6-4dc1-c10d-34d194db0b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's train!\n",
        "gen_model.fit(x_rnn_array, y_rnn_array,\n",
        "          batch_size=256,\n",
        "          epochs= 5,\n",
        "          callbacks=[gen_callback, checkpoint],\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3432/3433 [============================>.] - ETA: 0s - loss: 0.7622\n",
            "Seed: \"<start> when siblings judy and peter discover a board game\"\n",
            "<start> when siblings judy and peter discover a board game of evidence that suggests that they must resist . goofy lucas and the the living parade give way to monsters their lives to become a covert courier . when they get their father's own life\n",
            "3433/3433 [==============================] - 147s 43ms/step - loss: 0.7622\n",
            "Epoch 2/5\n",
            "3433/3433 [==============================] - 143s 42ms/step - loss: 0.7550\n",
            "Epoch 3/5\n",
            "3433/3433 [==============================] - 145s 42ms/step - loss: 0.7538\n",
            "Epoch 4/5\n",
            "3433/3433 [==============================] - 147s 43ms/step - loss: 0.7479\n",
            "Epoch 5/5\n",
            "3433/3433 [==============================] - 145s 42ms/step - loss: 0.7445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5abc6b7390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlnXFSUQYzZx"
      },
      "source": [
        "gen_model.save_weights('/content/drive/My Drive/CS230/Models/bidirectional')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34TOc4dQ0hyB",
        "outputId": "92511498-849b-4342-acd6-19d469baaf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model.evaluate(x_rnn_array, y_rnn_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27461/27461 [==============================] - 169s 6ms/step - loss: 0.7174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7174374461174011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGXqY_VV854v"
      },
      "source": [
        "# Let's choose several seeds:\n",
        "\n",
        "string_seed0 = 'judy and peter discover a board game that will'\n",
        "string_seed1 = 'CS230 students met a year ago for the'\n",
        "string_seed2 = 'professor andrew is on a mission to' \n",
        "string_seed3 = 'professor andrew goes on an adventure to'\n",
        "string_seed4 = 'CS230 students discover a'\n",
        "string_seed5 = 'a group of friends decides to go out for'\n",
        "\n",
        "def model_generate_text(model = gen_model, seed = string_seed1, length = 100, greedy = False, verbose = True, endtok=True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    \n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    if endtok == True:\n",
        "      while i != end and count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    else:\n",
        "      while count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd0S1dkd_0jP",
        "outputId": "b66c9ad2-116c-453d-9f19-a64b0f78569e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model: \n",
        "\n",
        "#text0, output0 = model_generate_text(model = gen_model, seed = string_seed0, length = 65, greedy = True)\n",
        "#text0, output0 = model_generate_text(model = gen_model, seed = string_seed0, length = 65, greedy = False)\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" GREEDY \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text6, output6 = model_generate_text(model = gen_model, seed = string_seed1, length = 50, greedy = True)\n",
        "text7, output7 = model_generate_text(model = gen_model, seed = string_seed2, length = 50, greedy = True)\n",
        "text8, output8 = model_generate_text(model = gen_model, seed = string_seed3, length = 50, greedy = True)\n",
        "text9, output9 = model_generate_text(model = gen_model, seed = string_seed4, length = 50, greedy = True)\n",
        "text10, output10 = model_generate_text(model = gen_model, seed = string_seed5, length = 50, greedy = True)\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "CS230 students met a year ago for the first time . <end>\n",
            "professor andrew is on a mission to find love and murder with every room beautiful ashley brown . as tom tries to balance the night with her fianc√© she has been violently after all . ultimately it is all the first time to pass orders to sell them into the zoo to infiltrate the crew hot on\n",
            "professor andrew goes on an adventure to the top of the ordinary . <end>\n",
            "CS230 students discover a dark conspiracy behind an explosion with a mysterious past despite a mad array of programming . <end>\n",
            "a group of friends decides to go out for a role that will prove her business succeeds in the passage of his family his zoo florence is confronted with jack taylor who gets thrust into the world even if the clouds government overdose all have been fired . trying on ice makes a surprising face with a beautiful celebrity\n",
            " \n",
            "__________________________________________________\n",
            " \n",
            "CS230 students met a year ago for the first time . <end>\n",
            "professor andrew is on a mission to find their love for his own kidnapping experiences . in her journey home for destroying the village in british columbia . <end>\n",
            "professor andrew goes on an adventure to the last official jimmy promises to win the heart of the robbery . <end>\n",
            "CS230 students discover a cache of tactics and growing up fires in why decline are unlikely she loved . <end>\n",
            "a group of friends decides to go out for a certain mature plan an old abandoned love goes horribly too wrong . <end>\n",
            " \n",
            "____________________ GREEDY ____________________\n",
            " \n",
            "CS230 students met a year ago for the first time . <end>\n",
            "professor andrew is on a mission to find their love for his own kidnapping rather than live . <end>\n",
            "professor andrew goes on an adventure to the real world has ever imagined <end>\n",
            "CS230 students discover a cache of tactics about a violent and exciting story that also happened to him and his life . <end>\n",
            "a group of friends decides to go out for a date . <end>\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6t-V-bi3_YE"
      },
      "source": [
        "##STEP 4 // TRAIN CONCATENATED GRU RNN WITH ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfB_V8Ih7vVA",
        "outputId": "fa09f660-291f-43c5-f95f-934841cf3be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### RNN LANGUAGE MODEL / WITH ATTENTION ###\n",
        "# By: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "h1 = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Two GRU Layers\n",
        "h2 = GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal')(h1)\n",
        "h3 = GRU(256, name = 'GRU2', return_sequences= True, kernel_initializer = 'glorot_normal')(h2)\n",
        "\n",
        "# Concatenate both GRU Layer Outputs\n",
        "h4 = Concatenate()([h1,h2,h3])\n",
        "\n",
        "# Attention done in several steps\n",
        "a = Dense(1, use_bias=False, activation='linear')(h4)\n",
        "a = Permute((2, 1))(a)\n",
        "a = Flatten()(a)\n",
        "a = Activation('softmax')(a)\n",
        "h = Dot(axes = [1,1])([a,h3])\n",
        "\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1', kernel_initializer = 'he_normal')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2', kernel_initializer = 'he_normal')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "\n",
        "gen_model2 = Model(inputs = seq_input, outputs = next_word)\n",
        "gen_model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "miniseq (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 64)       640064      miniseq[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "GRU1 (GRU)                      (None, 10, 256)      247296      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "GRU2 (GRU)                      (None, 10, 256)      394752      GRU1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10, 576)      0           embedding[0][0]                  \n",
            "                                                                 GRU1[0][0]                       \n",
            "                                                                 GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10, 1)        576         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 1, 10)        0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 10)           0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 256)          0           activation[0][0]                 \n",
            "                                                                 GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          131584      dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 2560)         1313280     dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "final (Dense)                   (None, 10000)        25610000    dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 28,337,552\n",
            "Trainable params: 28,337,552\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLbBq4WReXd"
      },
      "source": [
        "# Functions to produce text with our Attention RNN\n",
        "\n",
        "every = 5\n",
        "\n",
        "def generate_text2(epoch, _):\n",
        "  # This second function prints generated text at end of every few epochs\n",
        "  if epoch%every == 0:\n",
        "    print()\n",
        "    input = 'when siblings judy and peter discover a board game that'\n",
        "    print('Seed: \"' + input + '\"')\n",
        "    output = []\n",
        "    x_in = np.array(tokenizer.texts_to_sequences([input])[0])\n",
        "    i = -1\n",
        "    count = 0\n",
        "    while i != end and count < 35:     \n",
        "      preds = gen_model2.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      i = sample(preds)\n",
        "      x_in = np.append(x_in[1:],i)\n",
        "      output.append(i)\n",
        "      count+=1\n",
        "    print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "\n",
        "\n",
        "# Defining our callbacks - reusing code from previous model:\n",
        "checkpoint2 = ModelCheckpoint(filepath='model2',\n",
        "                             frequency = \"epoch\",\n",
        "                             save_weights_only = True,\n",
        "                             verbose = 0)\n",
        "\n",
        "gen_callback2 = LambdaCallback(on_epoch_end=generate_text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9TN3TPK8PYO",
        "outputId": "5a0f7396-b250-4603-9806-e56b745e731b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = Adamax(learning_rate=0.00000001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "gen_model2.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btjpFd9iY5aR",
        "outputId": "a6df8641-e44e-4a8c-8ba0-f03c64e9709f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model2.load_weights('/content/drive/My Drive/CS230/Models/attention')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f574cde2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoQNLijn8YIA"
      },
      "source": [
        "#Let's train!\n",
        "gen_model2.fit(x_rnn_array, y_rnn_array,\n",
        "          batch_size=256,\n",
        "          epochs=15,\n",
        "          callbacks=[gen_callback2, checkpoint2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NAlPdi3avnM"
      },
      "source": [
        "gen_model2.save_weights('/content/drive/My Drive/CS230/Models/attention')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_4Iq1dsweyk",
        "outputId": "fe963acb-d48f-4394-812c-567bd0a786ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model2.evaluate(x_rnn_array, y_rnn_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27461/27461 [==============================] - 134s 5ms/step - loss: 0.9059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9059416055679321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYsMM6PmdO8w",
        "outputId": "5c6ff141-cdf8-4fdf-ac91-c2c0280abf15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model:2  \n",
        "\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model2, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model2, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model2, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model2, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model2, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model2, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model2, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model2, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model2, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model2, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" GREEDY \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text6, output6 = model_generate_text(model = gen_model2, seed = string_seed1, length = 50, greedy = True)\n",
        "text7, output7 = model_generate_text(model = gen_model2, seed = string_seed2, length = 50, greedy = True)\n",
        "text8, output8 = model_generate_text(model = gen_model2, seed = string_seed3, length = 50, greedy = True)\n",
        "text9, output9 = model_generate_text(model = gen_model2, seed = string_seed4, length = 50, greedy = True)\n",
        "text10, output10 = model_generate_text(model = gen_model2, seed = string_seed5, length = 50, greedy = True)\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "CS230 students met a year ago for the perfect event . soon after they arrive we meet may come they have an her quest to discover the truth about the death of her mother . <end>\n",
            "professor andrew is on a mission to individual strip dropping a great career with back out all life to the spine but only he can get himself close behind by the uncle's version of ireland she is befriended by the volatile sir jim parent emma our only key point for killer rather bizarre thief maya and old\n",
            "professor andrew goes on an adventure to theme camp after a car accident . his former wife is linda the only person to trust her plan to be ex boys . social problems start nowhere he needs to kill seeing him that he and his next time prot√©g√© bruce make life in her one set for its\n",
            "CS230 students discover a sooner rapidly damaged ninja drive for a . enter closest and attempts to fix ecstasy engaging in a self destructive story involving money and frank and his crazy american sidekick in the british hills . <end>\n",
            "a group of friends decides to go out for their hotel to argentina come true . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n",
            "CS230 students met a year ago for the play talks that there is enough for a good ride from home on board . but can tommy make something more trouble he's blows out on his partners to pursue it together . <end>\n",
            "professor andrew is on a mission to writing action as the aristocratic kid follows him . actually evading the will she makes a pact with a no holds answers for these and dangerous supernatural creatures in order to save themselves their drinking particularly their love holidays from a truly striking up . the park fathers on both\n",
            "professor andrew goes on an adventure to 90 wonder about the murder and work of screenwriter block and his sexy young son and grandfather . the pair are forced into a newly unlikely pursuit that will save their entire lives . <end>\n",
            "CS230 students discover a script 5 protector drunken knowledge of a coffin and friends then train the internet to a hit plot which will escape his previous and in the process . through a bite they gradually split of humanity in the same situation . <end>\n",
            "a group of friends decides to go out for their land before outer space . but other twists are . . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n",
            "____________________ GREEDY ____________________\n",
            " \n",
            "CS230 students met a year ago for the perfect plan feeding them right beyond each new unexpected ways . <end>\n",
            "professor andrew is on a mission to heavily southern factories in the united states . <end>\n",
            "professor andrew goes on an adventure to talent on it and threaten to find someone who was trying to kill him vicious black 11 gay people . <end>\n",
            "CS230 students discover a casino rapidly damaged racing in a north african national congress . traces the couple to third through 4 years long by some of them disappear . <end>\n",
            "a group of friends decides to go out for their land . luckily he is coming up to find that of the ordinary owner of the war ocean line once again . <end>\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQT8wd2SQzo"
      },
      "source": [
        "## STEP 4 // EVALUATE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPZWpwlTeF1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "univ_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-osxCTZy_L"
      },
      "source": [
        "# EVALUATE BLEU & COSINE SIMILARITY ON THE TEST SET\n",
        "\n",
        "def cosine_sim(x,y):\n",
        "    num = np.sum(x*y)\n",
        "    den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
        "    return num/float(den)\n",
        "\n",
        "def evaluate_gen(version, greedy = True):\n",
        "  bleu = []\n",
        "  sim = []\n",
        "  fun = model_generate_text\n",
        "  if version == 1: \n",
        "    model = gen_model\n",
        "  else:\n",
        "    model = gen_model2   \n",
        "  \n",
        "  for j, synopsis in enumerate(testtokens):\n",
        "    #From test set:\n",
        "    input = tokenizer.sequences_to_texts([synopsis[:10]])[0]\n",
        "    output_test = synopsis[10:]\n",
        "    output_test_string = tokenizer.sequences_to_texts([output_test])[0]\n",
        "    output_test_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output_test]\n",
        "    emb_test = univ_embed([output_test_string])\n",
        "    l = len(synopsis)-10\n",
        "\n",
        "\n",
        "    #From model:\n",
        "    _, output = fun(model = model, seed = input, length = l, greedy = greedy, verbose = False, endtok = False)\n",
        "    output_string = tokenizer.sequences_to_texts([output])[0]\n",
        "    output_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output]\n",
        "    emb = univ_embed([output_string])\n",
        "    #Similarity Scores:\n",
        "    b = sentence_bleu([output_test_list], output_list, smoothing_function=SmoothingFunction().method2)\n",
        "    s = cosine_sim(emb, emb_test)\n",
        "\n",
        "    if j%100 == 0: \n",
        "      print(j, \" done!\")\n",
        "      #print(\"bleu: \", b)\n",
        "      #print(\"sim: \", s)\n",
        "\n",
        "    bleu.append(b)\n",
        "    sim.append(s)\n",
        "  \n",
        "  bleu_score = np.mean(bleu)\n",
        "  sim_score = np.mean(sim)\n",
        "  #print(\"BLEU: \", bleu_score)\n",
        "  #print(\"COS. SIMILARITY: \", sim_score)\n",
        "  return bleu_score, sim_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TsBUNBiHPc_",
        "outputId": "fb7f0902-c70f-4726-c53c-ac710d4d4aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"RNN Bid. Performance:\")\n",
        "bleu_score_RNN, sim_score_RNN = evaluate_gen(1)\n",
        "\n",
        "print(\"----------- RNN Bid. Performance -----------\")\n",
        "print(\"BLEU: \", np.round(bleu_score_RNN,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score_RNN,4))\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN Bid. Performance:\n",
            "----------- RNN Bid. Performance -----------\n",
            "BLEU:  0.0663\n",
            "COS. SIMILARITY:  0.2482\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb06A4DIaxSc",
        "outputId": "133de10b-5aaf-428c-b01b-b958cdf6d850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Attention Performance:\")\n",
        "bleu_score_att, sim_score_att = evaluate_gen(2)\n",
        "\n",
        "print(\"-------- Attention Performance --------\")\n",
        "print(\"BLEU: \", np.round(bleu_score_att,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score_att,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention Performance:\n",
            "-------- Attention Performance --------\n",
            "BLEU:  0.0646\n",
            "COS. SIMILARITY:  0.2425\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
