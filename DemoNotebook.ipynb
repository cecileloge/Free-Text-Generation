{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS230 // Model Demo",
      "provenance": [],
      "collapsed_sections": [
        "-XuY71GfoOlL",
        "mzVUh3ugx4-7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cecileloge/Free-Text-Generation/blob/main/DemoNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Model Demo (Bidirectional Model & Encoder-Decoder)\n",
        "\n",
        "\n",
        "*   STEP 1 IMPORT MODEL & UTILS\n",
        "*   STEP 2 DEMO\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "3f26ff2b-210a-4697-b713-ca6a4e9c96b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP 0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ10uNzDw4u-",
        "outputId": "25164984-8f13-4f52-9310-0e5836b28f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install colorama\n",
        "from colorama import Fore"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Dot, Permute\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply, Flatten, BatchNormalization, Add\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhS49cFRUnhO"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShRUetCRUOTW"
      },
      "source": [
        "## STEP 1 // IMPORT MODEL & UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_gijjWJUl0v"
      },
      "source": [
        "# TOKENIZE\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 10000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] \n",
        "\n",
        "# UTILS\n",
        "win_len = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wux1t8arU-jW",
        "outputId": "4d133dd3-e3f7-4aaf-d476-ca6fef5b68f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### RNN LANGUAGE MODEL ###\n",
        "# By: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Two BIDIRECTIONAL GRU Layers\n",
        "h = Bidirectional (GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal'))(h)\n",
        "h = Bidirectional (GRU(256, name = 'GRU2', kernel_initializer = 'glorot_normal'))(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "model = Model(inputs = seq_input, outputs = next_word)\n",
        "\n",
        "# COMPILE & IMPORT TRAINED WEIGHTS\n",
        "opt = Adamax(learning_rate=0.001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "model.compile(loss=loss, optimizer=opt)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/CS230/Models/bidirectional')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe0d64e32e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZXFWEjA454Y",
        "outputId": "0008bdfc-9566-4848-d84e-bc4dcc4d4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_genres = 20\n",
        "# Start with the ENCODER (input is genretrain)\n",
        "encoder_input = Input(shape=(num_genres,))\n",
        "encoder = Dense(256, activation = 'relu', kernel_initializer = 'he_normal')(encoder_input)\n",
        "# The state will then be used as input for the decoder\n",
        "\n",
        "\n",
        "# Input & Embedding for DECODER \n",
        "decoder_input = Input(shape=(win_len,))\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(decoder_input)\n",
        "\n",
        "# Three GRU Layers\n",
        "h = GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal')(h, initial_state=encoder)\n",
        "h = GRU(256, name = 'GRU2', return_sequences= True, kernel_initializer = 'glorot_normal')(h)\n",
        "h = GRU(256, name = 'GRU3', kernel_initializer = 'glorot_normal')(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1', kernel_initializer = 'he_normal')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2', kernel_initializer = 'he_normal')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "# The model to train:\n",
        "encod_model = Model([encoder_input, decoder_input], next_word)\n",
        "\n",
        "# COMPILE & IMPORT TRAINED WEIGHTS\n",
        "opt = Adamax(learning_rate=0.001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "encod_model.compile(loss=loss, optimizer=opt)\n",
        "\n",
        "encod_model.load_weights('/content/drive/My Drive/CS230/Models/encoder')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe047821f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO5_nAI1wmj"
      },
      "source": [
        "# DEMO FUNCTIONS FOR CHOOSE YOUR OWN ADVENTURE\n",
        "\n",
        "end = tokenizer.texts_to_sequences([['<end>']])[0][0] \n",
        "start = tokenizer.texts_to_sequences([['<start>']])[0][0] \n",
        "dicke = tokenizer.texts_to_sequences([[\"dickens'\"]])[0][0]\n",
        "\n",
        "def top_n(preds, n):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "\n",
        "  out = np.argpartition(preds, -n)[-n:]\n",
        "  return out+1\n",
        "\n",
        "def model_next(start = True, seed = 'we have come to think that'):\n",
        "    if start: seed = '<START> '+seed\n",
        "    print(Fore.LIGHTBLUE_EX + seed)\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([seed]), truncating='pre', maxlen=10)\n",
        "    \n",
        "    preds = model.predict(x_in, verbose=0)[0]\n",
        "    options = top_n(preds, 5)\n",
        "    a = tokenizer.sequences_to_texts([[options[0]]])[0]\n",
        "    b = tokenizer.sequences_to_texts([[options[1]]])[0]\n",
        "    c = tokenizer.sequences_to_texts([[options[2]]])[0]\n",
        "    d = tokenizer.sequences_to_texts([[options[3]]])[0]\n",
        "    e = tokenizer.sequences_to_texts([[options[4]]])[0]\n",
        "    \n",
        "    print(Fore.BLACK + 'Options: 1.{} , 2.{} , 3.{} , 4.{}, 5.{} '.format(a,b,c,d,e))\n",
        "    print(Fore.BLACK + \"Select your next word! (input the number)\")\n",
        "\n",
        "    choice = input()\n",
        "    choice = int(choice)\n",
        "    newseed = seed+\" \"+tokenizer.sequences_to_texts([[options[choice-1]]])[0]\n",
        "\n",
        "\n",
        "    \n",
        "    return newseed, options[choice-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8kcI0Z-0Of1"
      },
      "source": [
        "# DEMO FUNCTIONS FOR FULL SAMPLES\n",
        "\n",
        "def sample(preds, greedy = False):\n",
        "  # This first function samples the next word based on the output logits from the model\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "  samp = np.random.multinomial(1, preds, 1)\n",
        "  if greedy: \n",
        "    out = max(1, np.argmax(preds))\n",
        "  else: \n",
        "    out = np.argmax(samp)\n",
        "  return out+1\n",
        "\n",
        "\n",
        "def model_generate_text(seed, length = 35, greedy = False, verbose = True, endtok=True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    \n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    if endtok == True:\n",
        "      while i != end and count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    else:\n",
        "      while count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output\n",
        "\n",
        "# Genre Utils\n",
        "listgenre = ['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy','foreign', \n",
        "             'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi','thriller', 'tv_movie', 'war', 'western']\n",
        "dictgenre = {listgenre[i] : i for i in range(len(listgenre))}\n",
        "\n",
        "def genre_generate(seed, genre = ['drama'], length = 35, greedy = False, verbose = True):\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "    genre_in = np.zeros((1,20))\n",
        "    for g in genre:\n",
        "      i = dictgenre[g]\n",
        "      genre_in[:,i] = 1\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    v = 0\n",
        "    while i != end and count <length:     \n",
        "      preds = encod_model.predict([genre_in, x_in], verbose=0)[0]\n",
        "      i = sample(preds, greedy=greedy)\n",
        "      x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "      output.append(i)\n",
        "      count +=1\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output\n",
        "\n",
        "def generate_n(seed,n):\n",
        "  print(\"ADVENTURE:\")\n",
        "  genre_generate(seed, genre = ['adventure'], greedy = False)\n",
        "  print(\"FANTASY:\")\n",
        "  genre_generate(seed, genre = ['fantasy'], greedy = False)\n",
        "  print(\"THRILLER CRIME:\")\n",
        "  genre_generate(seed, genre = ['thriller','crime'], greedy = False)\n",
        "  print(\"RANDOM:\")\n",
        "  for i in range(n-1):\n",
        "    model_generate_text(seed)\n",
        "  model_generate_text(seed, greedy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--vwpXqo0lA9"
      },
      "source": [
        "def fun_demo_start():\n",
        "  print(\"What's your seed?\")\n",
        "  text_input = input()\n",
        "  return text_input.lower()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWE89EOeaxml"
      },
      "source": [
        "## STEP 2 // IT'S DEMO TIME!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsvQyoEg06KQ",
        "outputId": "22f501cc-b8b0-44ae-c4fc-74913a9c3d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DEMO FULL SAMPLE / RANDOM & BY GENRE\n",
        "seed = fun_demo_start()\n",
        "generate_n(seed, 5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What's your seed?\n",
            "cs230 students will meet on campus to study\n",
            "ADVENTURE:\n",
            "cs230 students will meet on campus to study storms by evil beings from the creator of the army and nature's plague . the fourth may be husband and ten young friends . survived them he finds himself exploring the telekinetic past while he\n",
            "FANTASY:\n",
            "cs230 students will meet on campus to study master hulk to guide the nazis to form a power and run back into egypt for years . together they finds himself with a russian soldier trying to determine the killer themselves . <end>\n",
            "THRILLER CRIME:\n",
            "cs230 students will meet on campus to study meat a life like deadly fish book system . . . or stand . <end>\n",
            "RANDOM:\n",
            "cs230 students will meet on campus to study oil on them . <end>\n",
            "cs230 students will meet on campus to study vampires who threaten them to enter the town alive . <end>\n",
            "cs230 students will meet on campus to study seven timing life . <end>\n",
            "cs230 students will meet on campus to study 12 30 minutes before all seems destined of . <end>\n",
            "cs230 students will meet on campus to study vampires after the newlyweds learn that age is not his final competition <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvVNsp90fkxm",
        "outputId": "be179403-3468-432d-a882-39f20155277f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DEMO WORD BY WORD \"CHOOSE YOUR OWN ADVENTURE\" / RANDOM\n",
        "seed = fun_demo_start()\n",
        "seed, a = model_next(start = True, seed = seed)\n",
        "while a != end:\n",
        "  seed, a =  model_next(start = False, seed = seed)\n",
        "\n",
        "print(Fore.LIGHTBLUE_EX + \"Well done! Here is your story:\")\n",
        "print(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What's your seed?\n",
            "cs230 students are meeting at school today to study\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study\n",
            "\u001b[30mOptions: 1.king , 2.destruction , 3.robots , 4.rush, 5.various \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "5\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various\n",
            "\u001b[30mOptions: 1.images , 2.stories , 3.unseen , 4.creatures, 5.college \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "4\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures\n",
            "\u001b[30mOptions: 1.she , 2.from , 3.they , 4.in, 5.living \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "5\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living\n",
            "\u001b[30mOptions: 1.from , 2.life , 3.work , 4.large, 5.in \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "5\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in\n",
            "\u001b[30mOptions: 1.new , 2.a , 3.rio , 4.the, 5.las \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "3\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio\n",
            "\u001b[30mOptions: 1.gone , 2.attacks , 3.james , 4.., 5.although \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "4\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio .\n",
            "\u001b[30mOptions: 1.when , 2.the , 3.now , 4.<end>, 5.but \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "2\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the\n",
            "\u001b[30mOptions: 1.machine , 2.boys , 3.pair , 4.trip, 5.film \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "1\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine\n",
            "\u001b[30mOptions: 1.begins , 2.has , 3.becomes , 4.goes, 5.is \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "1\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins\n",
            "\u001b[30mOptions: 1.at , 2.off , 3.out , 4.as, 5.when \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "4\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as\n",
            "\u001b[30mOptions: 1.well , 2.their , 3.the , 4.an, 5.a \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "1\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as well\n",
            "\u001b[30mOptions: 1.by , 2.<end> , 3.and , 4.as, 5.. \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "5\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as well .\n",
            "\u001b[30mOptions: 1.the , 2.. , 3.and , 4.<end>, 5.as \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "2\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as well . .\n",
            "\u001b[30mOptions: 1..a , 2.they , 3.the , 4.., 5.<end> \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "4\n",
            "\u001b[94m<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as well . . .\n",
            "\u001b[30mOptions: 1.but , 2.after , 3.as , 4.<end>, 5.. \n",
            "\u001b[30mSelect your next word! (input the number)\n",
            "4\n",
            "\u001b[94mWell done! Here is your story:\n",
            "<START> cs230 students are meeting at school today to study various creatures living in rio . the machine begins as well . . . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}