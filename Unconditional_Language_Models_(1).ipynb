{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS230 // Unconditional Language Models (1/2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-XuY71GfoOlL",
        "_TBM529kn9pG",
        "mzVUh3ugx4-7",
        "N_73CJ7MZ6k5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Unconditional Language Models (4.1 & 4.3)\n",
        "\n",
        "\n",
        "*   STEP 1 TOKENIZE THE DATA\n",
        "*   STEP 2 PREPROCESS INTO SMALLER SEQUENCES FOR TRAINING\n",
        "*   STEP 3 TRAIN BASELINE GRU RNN TO PRODUCE TEXT\n",
        "*   STEP 4 TRAIN GATED CNN WITH RESIDUAL\n",
        "*   STEP 5 EVALUATE RESULTS (BLEU & UNIVERSAL COSINE SIMILARITY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "5431d24b-df44-4ada-d33c-ea34376d43e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP 0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply, Flatten, BatchNormalization, Add\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgJUkSeVz3Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "train = pd.read_csv('/content/drive/My Drive/CS230/finaldata_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/CS230/finaldata_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8ZuOz2VzcK",
        "outputId": "4501bac9-9488-464d-a694-5ab03bdd11cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.head(5).iloc[:, :10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "      <th>title</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>length</th>\n",
              "      <th>num_genres</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['animation', 'comedy', 'family']</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>7.7</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['adventure', 'fantasy', 'family']</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['romance', 'comedy']</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>6.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['comedy']</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>5.7</td>\n",
              "      <td>173.0</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
              "      <td>Heat</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>55</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     genres  ... animation\n",
              "0         ['animation', 'comedy', 'family']  ...         1\n",
              "1        ['adventure', 'fantasy', 'family']  ...         0\n",
              "2                     ['romance', 'comedy']  ...         0\n",
              "3                                ['comedy']  ...         0\n",
              "4  ['action', 'crime', 'drama', 'thriller']  ...         0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIbez-9WM-l",
        "outputId": "c16f99c9-f08a-406f-8189-95eaa3c15a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "data['length'].plot(kind='hist', alpha=0.7, color='orange')\n",
        "plt.title('Histogram Snippet Length')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Average Snippet is: ', int(np.mean(data.length)), ' words.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average Snippet is:  48  words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBM529kn9pG"
      },
      "source": [
        "## STEP1 // LET'S TOKENIZE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7zJQEuHZGH"
      },
      "source": [
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]\n",
        "train['overview_stop']=['<START> '+a+' <END>' for a in train.overview_stop]\n",
        "test['overview_stop']=['<START> '+a+' <END>' for a in test.overview_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhzJv7vfoD1"
      },
      "source": [
        "# Tokenizing / Create a Tokenizer object\n",
        "\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 10000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "seqtokens = tokenizer.texts_to_sequences(liststrings)\n",
        "traintokens = tokenizer.texts_to_sequences(list(train.overview_stop))\n",
        "testtokens = tokenizer.texts_to_sequences(list(test.overview_stop))\n",
        "\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5g55F2yXtw"
      },
      "source": [
        "tokenizer.sequences_to_texts(seqtokens)[:5] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL58tZAufQPo"
      },
      "source": [
        "sequnk = [[1 if x ==1 else 0 for x in s] for s in seqtokens]\n",
        "count_unk = [np.sum(x) for x in sequnk]\n",
        "freq_unk = [float(np.sum(x)/len(x)) for x in sequnk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMy_odgfdaS",
        "outputId": "7ab2de6a-1288-4288-e074-72915d2e8b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reminder of the length of the snippets...\n",
        "print('Average Number of <UNK>s is: ', np.round(np.mean(count_unk),1))\n",
        "print('Max Number of <UNK>s is: ', np.round(np.max(count_unk),1))\n",
        "\n",
        "print('Average Freq of <UNK>s is: ', np.round(np.mean(freq_unk),3))\n",
        "print('Max Freq of <UNK>s is: ', np.round(np.max(freq_unk),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Number of <UNK>s is:  2.4\n",
            "Max Number of <UNK>s is:  12\n",
            "Average Freq of <UNK>s is:  0.041\n",
            "Max Freq of <UNK>s is:  0.121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLC-Jkfo2ed0"
      },
      "source": [
        "lengths = [len(x) for x in seqtokens]\n",
        "maxlen = max(lengths)\n",
        "m = len(seqtokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ij5wJTE0zOn"
      },
      "source": [
        "x = pad_sequences(seqtokens, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDzX1yyo3add"
      },
      "source": [
        "y = np.array(data[['drama','comedy','thriller','romance','adventure','family']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLiH0nc03yAX",
        "outputId": "e36d2b29-1616-439c-def4-aa87d0a2b203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"x shape: \", x.shape)\n",
        "print(\"y shape: \", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape:  (20691, 136)\n",
            "y shape:  (20691, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGL83TyZMtE"
      },
      "source": [
        "dict_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzVUh3ugx4-7"
      },
      "source": [
        "##STEP2 // PRE-PROCESS INTO SMALLER SEQUENCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wgKn6LrZ5mP",
        "outputId": "ebea0b9b-c40e-4120-fc02-a0996554d0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### WORD-LEVEL LANGUAGE MODEL WITH A FIXED WINDOW ###\n",
        "# Script inspired in parts by the CHAR-LEVEL model: lstm_text_generation.py by fchollet https://github.com/keras-team/keras\n",
        "# Adapted for this project by: ceciloge@stanford.edu\n",
        "\n",
        "# Preprocess the text into smaller sequences of words on one side (window length), and output next word on the other\n",
        "win_len = 10\n",
        "#tokens = list(compress(seqtokens, drama_filter))\n",
        "tokens = traintokens\n",
        "x_rnn = []\n",
        "y_rnn = []\n",
        "\n",
        "for j, text in enumerate(tokens):\n",
        "  if j%5000 == 0: print(\"We're at...\", j)\n",
        "  for i in range(len(text)-win_len):\n",
        "    x_rnn.append(text[i:i+win_len])\n",
        "    y_rnn.append(text[i+win_len])\n",
        "\n",
        "print(\"Total number of smaller sequences: \", len(x_rnn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're at... 0\n",
            "We're at... 5000\n",
            "We're at... 10000\n",
            "We're at... 15000\n",
            "We're at... 20000\n",
            "Total number of smaller sequences:  878744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqk-mv792NzP",
        "outputId": "a3bd2005-2315-4d32-8571-76a8629779d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turning our sequences into arrays\n",
        "x_rnn_array = np.array([np.array(s) for s in x_rnn])\n",
        "y_rnn_array = np.array([np.array(s) for s in y_rnn])-1\n",
        "print('x Shape: ',x_rnn_array.shape)\n",
        "print('y Shape: ',y_rnn_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Shape:  (878744, 10)\n",
            "y Shape:  (878744,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_73CJ7MZ6k5"
      },
      "source": [
        "##STEP3 // TRAIN A BASELINE RNN TO PRODUCE TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txulTMWD4XG1",
        "outputId": "e46b909a-e0b8-4c97-9be0-674ce0e33dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### RNN LANGUAGE MODEL ###\n",
        "# By: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Two GRU Layers\n",
        "h = GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal')(h)\n",
        "h = GRU(256, name = 'GRU2', kernel_initializer = 'glorot_normal')(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "gen_model = Model(inputs = seq_input, outputs = next_word)\n",
        "gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "miniseq (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 10, 64)            640064    \n",
            "_________________________________________________________________\n",
            "GRU1 (GRU)                   (None, 10, 256)           247296    \n",
            "_________________________________________________________________\n",
            "GRU2 (GRU)                   (None, 256)               394752    \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 2560)              1313280   \n",
            "_________________________________________________________________\n",
            "final (Dense)                (None, 10000)             25610000  \n",
            "=================================================================\n",
            "Total params: 28,336,976\n",
            "Trainable params: 28,336,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCO5_nAI1wmj"
      },
      "source": [
        "# Functions to produce text with our RNN model\n",
        "\n",
        "every = 5\n",
        "end = tokenizer.texts_to_sequences([['<end>']])[0][0] \n",
        "start = tokenizer.texts_to_sequences([['<start>']])[0][0] \n",
        "dicke = tokenizer.texts_to_sequences([[\"dickens'\"]])[0][0]\n",
        "\n",
        "def sample(preds, greedy = False):\n",
        "  # This first function samples the next word based on the output logits from the model\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "  samp = np.random.multinomial(1, preds, 1)\n",
        "  if greedy: \n",
        "    out = max(1, np.argmax(preds))\n",
        "  else: \n",
        "    out = np.argmax(samp)\n",
        "  return out+1\n",
        "\n",
        "def generate_text(epoch, _):\n",
        "  # This second function prints generated text at end of every few epochs\n",
        "  if epoch%every == 0:\n",
        "    print()\n",
        "    input = '<start> when siblings judy and peter discover a board game'\n",
        "    print('Seed: \"' + input + '\"')\n",
        "    output = []\n",
        "    x_in = np.array(tokenizer.texts_to_sequences([input])[0])\n",
        "    i = -1\n",
        "    count = 0\n",
        "    while i != end and count < 35:     \n",
        "      preds = gen_model.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      i = sample(preds)\n",
        "      x_in = np.append(x_in[1:],i)\n",
        "      output.append(i)\n",
        "      count+=1\n",
        "      \n",
        "    print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "\n",
        "# Defining our callbacks:\n",
        "checkpoint = ModelCheckpoint(filepath='model',\n",
        "                             frequency = \"epoch\",\n",
        "                             save_weights_only = True,\n",
        "                             verbose = 0)\n",
        "\n",
        "gen_callback = LambdaCallback(on_epoch_end=generate_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBy8VJxo8VMP",
        "outputId": "1f88d750-7bb1-4230-e533-00838827a1b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Optimizer, Loss & Compiling\n",
        "opt = Adamax(learning_rate=0.0001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "gen_model.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg2ayY64NgpU",
        "outputId": "caece889-6c75-40e8-eaeb-3bba6bac204d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model.load_weights('/content/drive/My Drive/CS230/Models/baseline')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8953608da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycqkPSz1zPI"
      },
      "source": [
        "# Let's train!\n",
        "gen_model.fit(x_rnn_array, y_rnn_array,\n",
        "          batch_size=256,\n",
        "          epochs= 20,\n",
        "          callbacks=[gen_callback, checkpoint],\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlnXFSUQYzZx"
      },
      "source": [
        "gen_model.save_weights('/content/drive/My Drive/CS230/Models/baseline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34TOc4dQ0hyB",
        "outputId": "56e570f6-90e7-47a6-d1b3-934a61e9f2f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model.evaluate(x_rnn_array, y_rnn_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27461/27461 [==============================] - 116s 4ms/step - loss: 0.8327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8326650261878967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGXqY_VV854v"
      },
      "source": [
        "# Let's choose several seeds:\n",
        "\n",
        "string_seed0 = 'judy and peter discover a board game that will'\n",
        "string_seed1 = 'CS230 students met a year ago for the'\n",
        "string_seed2 = 'professor andrew is on a mission to' \n",
        "string_seed3 = 'professor andrew goes on an adventure to'\n",
        "string_seed4 = 'CS230 students discover a'\n",
        "string_seed5 = 'a group of friends decides to go out for'\n",
        "\n",
        "def model_generate_text(model = gen_model, seed = string_seed1, length = 100, greedy = False, verbose = True, endtok = True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    \n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    if endtok == True:\n",
        "      while i != end and count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    else:\n",
        "      while count <length:     \n",
        "        preds = model.predict(x_in, verbose=0)[0]\n",
        "        i = sample(preds, greedy=greedy)\n",
        "        x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "        output.append(i)\n",
        "        count +=1\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd0S1dkd_0jP",
        "outputId": "ab4539a2-2f3a-406e-f5ff-197dd655d949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model: \n",
        "\n",
        "#text0, output0 = model_generate_text(model = gen_model, seed = string_seed0, length = 65, greedy = True)\n",
        "#text0, output0 = model_generate_text(model = gen_model, seed = string_seed0, length = 65, greedy = False)\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" GREEDY \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text6, output6 = model_generate_text(model = gen_model, seed = string_seed1, length = 50, greedy = True)\n",
        "text7, output7 = model_generate_text(model = gen_model, seed = string_seed2, length = 50, greedy = True)\n",
        "text8, output8 = model_generate_text(model = gen_model, seed = string_seed3, length = 50, greedy = True)\n",
        "text9, output9 = model_generate_text(model = gen_model, seed = string_seed4, length = 50, greedy = True)\n",
        "text10, output10 = model_generate_text(model = gen_model, seed = string_seed5, length = 50, greedy = True)\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "CS230 students met a year ago for the role of a local farmer . <end>\n",
            "professor andrew is on a mission to date a female new yorker whose long lost dad can be rescued . as he struggled to escape the stranger is determined to turn their kids away from him . the boy delivers strong children and the competition of his slow city featuring also numerous couples . three years later\n",
            "professor andrew goes on an adventure to take his men away from his girlfriend's money and sells his ex lover mom martin more dollars high professional faith instead . but what if to build it is a cover individuals was haunting . intrigued against his exclusive gender disaster it is now as a murder he can revive\n",
            "CS230 students discover a romantic battle – and skills for the french name of a science crew quickly foster isolated blood rooms . <end>\n",
            "a group of friends decides to go out for their destination off to confront his own death legacy . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n",
            "____________________ GREEDY ____________________\n",
            " \n",
            "CS230 students met a year ago for the wedding of a broadway teacher . there she acts for something that work no thrills discover that the derelict lives due to her own house . suffering from home she buys a seemingly kind she moves on her and she leaves her plight with his estranged parents for this to\n",
            "professor andrew is on a mission to date a young boy looking for a fresh buck room . he only run himself alone completely in japanese war city . <end>\n",
            "professor andrew goes on an adventure to take down the complications of her family friends and her own marriage . eventually she ends up falling victim to her husband . <end>\n",
            "CS230 students discover a plot to rob a warehouse in a country in the desert the doctor a lawyer is mistaken as a teenager and ray camping to capture . <end>\n",
            "a group of friends decides to go out for the farm and upcoming williams survives a huge book deep beyond his courtship and no opportunities in trying to make a slice of his dreams . <end>\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6t-V-bi3_YE"
      },
      "source": [
        "##STEP 4 // TRAIN A GATED CNN WITH RESIDUAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfB_V8Ih7vVA",
        "outputId": "a549296b-cc5e-452c-c6eb-d80557970d28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### GATED CNN LANGUAGE MODEL ###\n",
        "# Convolution Blocks consisting in: Conv1D with Gated Linear Unit \n",
        "# (Research: https://arxiv.org/abs/1612.08083 by Y. Dauphin)\n",
        "# Idea adapted for this project by: ceciloge@stanford.edu\n",
        "\n",
        "# Input & Embedding\n",
        "seq_input = Input(shape=(win_len,), name = 'miniseq')\n",
        "o0 = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(seq_input)\n",
        "\n",
        "# Block 1\n",
        "h1 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv11', kernel_initializer = 'glorot_normal')(o0)\n",
        "h1 = BatchNormalization()(h1)\n",
        "h2 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv12', kernel_initializer = 'glorot_normal')(o0)\n",
        "h2 = BatchNormalization()(h2)\n",
        "h2 = Activation(activations.sigmoid)(h2)\n",
        "o1 = Multiply()([h1, h2])\n",
        "\n",
        "# Block 2\n",
        "h1 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv21', kernel_initializer = 'glorot_normal')(o1)\n",
        "h1 = BatchNormalization()(h1)\n",
        "h2 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv22', kernel_initializer = 'glorot_normal')(o1)\n",
        "h2 = BatchNormalization()(h2)\n",
        "h2 = Activation(activations.sigmoid)(h2)\n",
        "o2 = Multiply()([h1, h2])\n",
        "\n",
        "# Block 3\n",
        "h1 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv31', kernel_initializer = 'glorot_normal')(o2)\n",
        "h1 = BatchNormalization()(h1)\n",
        "h2 = Conv1D(128, 4, strides=1, padding=\"causal\", name ='Conv32', kernel_initializer = 'glorot_normal')(o2)\n",
        "h2 = BatchNormalization()(h2)\n",
        "h2 = Add()([o1, h2]) #Residual from Block1\n",
        "h2 = Activation(activations.sigmoid)(h2)\n",
        "o3 = Multiply()([h1, h2])\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1', kernel_initializer = 'he_normal')(o3)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2', kernel_initializer = 'he_normal')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "gen_model2 = Model(inputs = seq_input, outputs = next_word[:,-1,:])\n",
        "gen_model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "miniseq (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 64)       640064      miniseq[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv12 (Conv1D)                 (None, 10, 128)      32896       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Conv11 (Conv1D)                 (None, 10, 128)      32896       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 10, 128)      512         Conv12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 10, 128)      512         Conv11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 10, 128)      0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 10, 128)      0           batch_normalization[0][0]        \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Conv22 (Conv1D)                 (None, 10, 128)      65664       multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv21 (Conv1D)                 (None, 10, 128)      65664       multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 10, 128)      512         Conv22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 10, 128)      512         Conv21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 10, 128)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 10, 128)      0           batch_normalization_2[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Conv32 (Conv1D)                 (None, 10, 128)      65664       multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 10, 128)      512         Conv32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Conv31 (Conv1D)                 (None, 10, 128)      65664       multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 10, 128)      0           multiply[0][0]                   \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10, 128)      512         Conv31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 10, 128)      0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 10, 128)      0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 10, 512)      66048       multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 10, 2560)     1313280     dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "final (Dense)                   (None, 10, 10000)    25610000    dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 10000)]      0           final[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 27,960,912\n",
            "Trainable params: 27,959,376\n",
            "Non-trainable params: 1,536\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLbBq4WReXd"
      },
      "source": [
        "# Functions to produce text with our Gated CNN model\n",
        "\n",
        "every = 5\n",
        "\n",
        "def generate_text2(epoch, _):\n",
        "  # This second function prints generated text at end of every few epochs\n",
        "  if epoch%every == 0:\n",
        "    print()\n",
        "    input = '<start> when siblings judy and peter discover a board game'\n",
        "    print('Seed: \"' + input + '\"')\n",
        "    output = []\n",
        "    x_in = np.array(tokenizer.texts_to_sequences([input])[0])\n",
        "    i = -1\n",
        "    count = 0\n",
        "    while i != end and count < 35:     \n",
        "      preds = gen_model2.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      i = sample(preds)\n",
        "      x_in = np.append(x_in[1:],i)\n",
        "      output.append(i)\n",
        "      count+=1\n",
        "    print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "\n",
        "\n",
        "# Defining our callbacks - reusing code from previous model:\n",
        "checkpoint2 = ModelCheckpoint(filepath='model2',\n",
        "                             frequency = \"epoch\",\n",
        "                             save_weights_only = True,\n",
        "                             verbose = 0)\n",
        "\n",
        "gen_callback2 = LambdaCallback(on_epoch_end=generate_text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9TN3TPK8PYO",
        "outputId": "f4bb0813-cd45-45d1-fe22-3cd3807e1feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = Adamax(learning_rate=0.0004)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "gen_model2.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btjpFd9iY5aR",
        "outputId": "7b1be9d7-a931-4911-b8bb-ad9f3fe86000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_model2.load_weights('/content/drive/My Drive/CS230/Models/gatedcnn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f89300b8780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoQNLijn8YIA",
        "outputId": "ff7ecff4-ae45-4d21-dc29-f64cf5d3e443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Let's train!\n",
        "gen_model2.fit(x_rnn_array, y_rnn_array,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          callbacks=[gen_callback2, checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3433/3433 [==============================] - ETA: 0s - loss: 3.7263\n",
            "Seed: \"<start> when siblings judy and peter discover a board game\"\n",
            "<start> when siblings judy and peter discover a board game of revenge with her run out world . <end>\n",
            "3433/3433 [==============================] - 412s 120ms/step - loss: 3.7263\n",
            "Epoch 2/5\n",
            "3433/3433 [==============================] - 410s 119ms/step - loss: 3.7259\n",
            "Epoch 3/5\n",
            "3433/3433 [==============================] - 409s 119ms/step - loss: 3.7251\n",
            "Epoch 4/5\n",
            "3433/3433 [==============================] - 408s 119ms/step - loss: 3.7242\n",
            "Epoch 5/5\n",
            "3433/3433 [==============================] - 410s 119ms/step - loss: 3.7240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88dc56ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NAlPdi3avnM"
      },
      "source": [
        "gen_model2.save_weights('/content/drive/My Drive/CS230/Models/gatedcnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_4Iq1dsweyk"
      },
      "source": [
        "gen_model2.evaluate(x_rnn_array, y_rnn_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYsMM6PmdO8w",
        "outputId": "8efc34f3-7504-41c4-a21d-4b0ab6f34e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model:2  \n",
        "\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = gen_model2, seed = string_seed1, length = 50)\n",
        "text2, output2 = model_generate_text(model = gen_model2, seed = string_seed2, length = 50)\n",
        "text3, output3 = model_generate_text(model = gen_model2, seed = string_seed3, length = 50)\n",
        "text4, output4 = model_generate_text(model = gen_model2, seed = string_seed4, length = 50)\n",
        "text5, output5 = model_generate_text(model = gen_model2, seed = string_seed5, length = 50)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" GREEDY \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text6, output6 = model_generate_text(model = gen_model2, seed = string_seed1, length = 50, greedy = True)\n",
        "text7, output7 = model_generate_text(model = gen_model2, seed = string_seed2, length = 50, greedy = True)\n",
        "text8, output8 = model_generate_text(model = gen_model2, seed = string_seed3, length = 50, greedy = True)\n",
        "text9, output9 = model_generate_text(model = gen_model2, seed = string_seed4, length = 50, greedy = True)\n",
        "text10, output10 = model_generate_text(model = gen_model2, seed = string_seed5, length = 50, greedy = True)\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "CS230 students met a year ago for the murders . <end>\n",
            "professor andrew is on a mission to save the accidents scramble to prove that . <end>\n",
            "professor andrew goes on an adventure to impress the thrust who would be all about in it in his friendship <end>\n",
            "CS230 students discover a pair of mysterious men in the middle of evil icon . <end>\n",
            "a group of friends decides to go out for her wedding so to learn about pat is half people in action the other of the mob will finally find that her disastrous affections to a wheelchair but misses his she heads for the thrill at his room . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n",
            "____________________ GREEDY ____________________\n",
            " \n",
            "CS230 students met a year ago for the most popular man in school . <end>\n",
            "professor andrew is on a mission to find the truth about the world . <end>\n",
            "professor andrew goes on an adventure to get up to the same family . <end>\n",
            "CS230 students discover a new drug robbery and the money to get up to the man of a new york neighbourhood . <end>\n",
            "a group of friends decides to go out for his own life and then are forced to make a new world . <end>\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQT8wd2SQzo"
      },
      "source": [
        "## STEP 4 // EVALUATE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPZWpwlTeF1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "univ_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-osxCTZy_L"
      },
      "source": [
        "# EVALUATE BLEU & COSINE SIMILARITY ON THE TEST SET\n",
        "\n",
        "def cosine_sim(x,y):\n",
        "    num = np.sum(x*y)\n",
        "    den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
        "    return num/float(den)\n",
        "\n",
        "def evaluate_gen(version, greedy = True):\n",
        "  bleu = []\n",
        "  sim = []\n",
        "  fun = model_generate_text\n",
        "  if version == 1: \n",
        "    model = gen_model\n",
        "  else:\n",
        "    model = gen_model2   \n",
        "  \n",
        "  for j, synopsis in enumerate(testtokens):\n",
        "    #From test set:\n",
        "    input = tokenizer.sequences_to_texts([synopsis[:10]])[0]\n",
        "    output_test = synopsis[10:]\n",
        "    output_test_string = tokenizer.sequences_to_texts([output_test])[0]\n",
        "    output_test_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output_test]\n",
        "    emb_test = univ_embed([output_test_string])\n",
        "    l = len(synopsis)-10\n",
        "\n",
        "\n",
        "    #From model:\n",
        "    _, output = fun(model = model, seed = input, length = l, greedy = greedy, verbose = False, endtok = False)\n",
        "    output_string = tokenizer.sequences_to_texts([output])[0]\n",
        "    output_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output]\n",
        "    emb = univ_embed([output_string])\n",
        "    #Similarity Scores:\n",
        "    b = sentence_bleu([output_test_list], output_list, smoothing_function=SmoothingFunction().method2)\n",
        "    s = cosine_sim(emb, emb_test)\n",
        "\n",
        "    if j%100 == 0: \n",
        "      print(j, \" done!\")\n",
        "      #print(\"bleu: \", b)\n",
        "      #print(\"sim: \", s)\n",
        "\n",
        "    bleu.append(b)\n",
        "    sim.append(s)\n",
        "  \n",
        "  bleu_score = np.mean(bleu)\n",
        "  sim_score = np.mean(sim)\n",
        "  print(\"BLEU: \", bleu_score)\n",
        "  print(\"COS. SIMILARITY: \", sim_score)\n",
        "  return bleu_score, sim_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TsBUNBiHPc_",
        "outputId": "88b2bd18-5bbb-4391-a5fe-f4ebfb28b261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"RNN Performance:\")\n",
        "bleu_score_RNN, sim_score_RNN = evaluate_gen(1)\n",
        "\n",
        "print(\"----------- RNN Performance -----------\")\n",
        "print(\"BLEU: \", np.round(bleu_score_RNN,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score_RNN,4))\n",
        "print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN Performance:\n",
            "----------- RNN Performance -----------\n",
            "BLEU:  0.0637\n",
            "COS. SIMILARITY:  0.2448\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb06A4DIaxSc",
        "outputId": "33eb08e7-3de6-44bf-fdf2-2f15c68c5d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Gated CNN Performance:\")\n",
        "bleu_score_CNN, sim_score_CNN = evaluate_gen(2)\n",
        "\n",
        "print(\"-------- Gated CNN Performance --------\")\n",
        "print(\"BLEU: \", np.round(bleu_score_CNN,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score_CNN,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gated CNN Performance:\n",
            "-------- Gated CNN Performance --------\n",
            "BLEU:  0.0714\n",
            "COS. SIMILARITY:  0.2215\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}