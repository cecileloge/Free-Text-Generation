{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS230 // Conditional Encoder-Decoder Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_TBM529kn9pG",
        "u8q73BterB80",
        "VhT0ICnio_C0",
        "3yijSQP5Yec7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Conditional Encoder-Decoder Model (5.2)\n",
        "\n",
        "\n",
        "*   STEP 1 TOKENIZE THE DATA\n",
        "*   STEP 2 PREPROCESS THE DATA FOR TRAINING\n",
        "*   STEP 3 BUILD & TRAIN THE ENCODER-DECODER MODEL\n",
        "*   STEP 4 LET'S TRY OUR TRAINED MODEL!\n",
        "*   STEP 5 EVALUATE RESULTS (BLEU & UNIVERSAL COSINE SIMILARITY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "e2424556-4f06-48ba-abd7-56ba6670d23f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgJUkSeVz3Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "train = pd.read_csv('/content/drive/My Drive/CS230/finaldata_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/CS230/finaldata_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8ZuOz2VzcK",
        "outputId": "9fef6c17-a02c-4658-c1c6-5123ca446b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.head(5).iloc[:, :10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "      <th>title</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>length</th>\n",
              "      <th>num_genres</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['animation', 'comedy', 'family']</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>7.7</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['adventure', 'fantasy', 'family']</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['romance', 'comedy']</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>6.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['comedy']</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>5.7</td>\n",
              "      <td>173.0</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
              "      <td>Heat</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>55</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     genres  ... animation\n",
              "0         ['animation', 'comedy', 'family']  ...         1\n",
              "1        ['adventure', 'fantasy', 'family']  ...         0\n",
              "2                     ['romance', 'comedy']  ...         0\n",
              "3                                ['comedy']  ...         0\n",
              "4  ['action', 'crime', 'drama', 'thriller']  ...         0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBM529kn9pG"
      },
      "source": [
        "## STEP1 // LET'S TOKENIZE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-RCyHAlIO5O"
      },
      "source": [
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]\n",
        "train['overview_stop']=['<START> '+a+' <END>' for a in train.overview_stop]\n",
        "test['overview_stop']=['<START> '+a+' <END>' for a in test.overview_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhzJv7vfoD1"
      },
      "source": [
        "# Tokenizing / Create a Tokenizer object\n",
        "\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 10000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "seqtokens = tokenizer.texts_to_sequences(liststrings)\n",
        "traintokens = tokenizer.texts_to_sequences(list(train.overview_stop))\n",
        "testtokens = tokenizer.texts_to_sequences(list(test.overview_stop))\n",
        "\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5g55F2yXtw",
        "outputId": "9df06988-85a3-4778-e1f1-5cd02238c634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.sequences_to_texts(seqtokens)[:2] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<start> led by woody andy's toys live happily in his room until andy's birthday brings buzz <UNK> onto the scene . afraid of losing his place in andy's heart woody plots against buzz . but when circumstances separate buzz and woody from their owner the duo eventually learns to put aside their differences . <end>\",\n",
              " \"<start> when siblings judy and peter discover an enchanted board game that opens the door to a magical world they unwittingly invite alan an adult who's been trapped inside the game for 26 years into their living room . <UNK> only hope for freedom is to finish the game which proves risky as all three find themselves running from giant <UNK> evil <UNK> and other terrifying creatures . <end>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8q73BterB80"
      },
      "source": [
        "##STEP2 // PREPROCESS THE DATA FOR TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGL83TyZMtE",
        "outputId": "fbb7a1a6-e2c2-4f5f-db62-726748075d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### WORD-LEVEL LANGUAGE MODEL WITH SEQ TO SEQ STRUCTURE ###\n",
        "# Script inspired in parts by the CHAR-LEVEL model: lstm_seq2seq.py by fchollet https://github.com/keras-team/keras\n",
        "# Adapted by: ceciloge@stanford.edu\n",
        "\n",
        "# PREPPING THE (INPUT GENRE) ENCODER DATA:\n",
        "\n",
        "genredata = np.array(data[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretrain = np.array(train[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretest = np.array(test[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "\n",
        "m = genretrain.shape[0]\n",
        "num_genres = genretrain.shape[1]\n",
        "print(\"Size of Training Set: \", m) \n",
        "print(\"Max sequence length for input (genres):\", num_genres) #num_encoder_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Training Set:  20277\n",
            "Max sequence length for input (genres): 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbPmn0QNrARc",
        "outputId": "47f4b007-e4a9-4b5b-b992-f5b5a06e5692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocess the text into smaller sequences of words on one side (window length), and output next word on the other\n",
        "win_len = 10\n",
        "tokens = traintokens\n",
        "genre_cond = [] #ENCODER\n",
        "x_input = [] #DECODER INPUT\n",
        "y_next = []  #DECODER OUTPUT\n",
        "\n",
        "for j, text in enumerate(tokens):\n",
        "  if j%5000 == 0: print(\"We're at...\", j)\n",
        "  for i in range(len(text)-win_len):\n",
        "    x_input.append(text[i:i+win_len])\n",
        "    y_next.append(text[i+win_len])\n",
        "    genre_cond.append(genretrain[j,:])\n",
        "\n",
        "print(\"Total number of smaller sequences: \", len(x_input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're at... 0\n",
            "We're at... 5000\n",
            "We're at... 10000\n",
            "We're at... 15000\n",
            "We're at... 20000\n",
            "Total number of smaller sequences:  878744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLYhmy3Fr_Gq",
        "outputId": "39280459-dd12-43d4-9e9f-75992d20e2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turning our sequences into arrays\n",
        "x_input_array = np.array([np.array(s) for s in x_input]) #Decoder Input\n",
        "y_next_array = np.array([np.array(s) for s in y_next])-1 #Decoder Output\n",
        "genre_array = np.array(genre_cond) #Encoder Input\n",
        "print('x Shape: ',x_input_array.shape)\n",
        "print('y Shape: ',y_next_array.shape)\n",
        "print('genre Shape: ',genre_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Shape:  (878744, 10)\n",
            "y Shape:  (878744,)\n",
            "genre Shape:  (878744, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhT0ICnio_C0"
      },
      "source": [
        "##STEP3 // BUILD & TRAIN THE ENCODER-DECODER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9a8aQ6vZ-Vs",
        "outputId": "aa318007-6748-41db-83df-c5a64d2598dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Start with the ENCODER (input is genretrain)\n",
        "encoder_input = Input(shape=(num_genres,))\n",
        "encoder = Dense(256, activation = 'relu', kernel_initializer = 'he_normal')(encoder_input)\n",
        "# The state will then be used as input for the decoder\n",
        "\n",
        "\n",
        "# Input & Embedding for DECODER \n",
        "decoder_input = Input(shape=(win_len,))\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(decoder_input)\n",
        "\n",
        "# Three GRU Layers\n",
        "h = GRU(256, name = 'GRU1', return_sequences= True, kernel_initializer = 'glorot_normal')(h, initial_state=encoder)\n",
        "h = GRU(256, name = 'GRU2', return_sequences= True, kernel_initializer = 'glorot_normal')(h)\n",
        "h = GRU(256, name = 'GRU3', kernel_initializer = 'glorot_normal')(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1', kernel_initializer = 'he_normal')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2', kernel_initializer = 'he_normal')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "# The model to train:\n",
        "modelgen = Model([encoder_input, decoder_input], next_word)\n",
        "modelgen.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 64)       640064      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          5376        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "GRU1 (GRU)                      (None, 10, 256)      247296      embedding[0][0]                  \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "GRU2 (GRU)                      (None, 10, 256)      394752      GRU1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "GRU3 (GRU)                      (None, 256)          394752      GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          131584      GRU3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 2560)         1313280     dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "final (Dense)                   (None, 10000)        25610000    dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 28,737,104\n",
            "Trainable params: 28,737,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0QgjEyu67II",
        "outputId": "deef35a9-e5b5-4d62-b4f1-4fd11ee258ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = Adamax(learning_rate=0.001)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "modelgen.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QhvuK617Xah",
        "outputId": "87e26c6d-7611-44cf-b51e-8ee85e545551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelgen.load_weights('/content/drive/My Drive/CS230/Models/encoder')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdf53e279e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8rJoBkGlYlH"
      },
      "source": [
        "modelgen.fit([genre_array, x_input_array], y_next_array,\n",
        "             batch_size = 256,\n",
        "             epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10tbYWMn7Kqs"
      },
      "source": [
        "modelgen.save_weights('/content/drive/My Drive/CS230/Models/encoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yijSQP5Yec7"
      },
      "source": [
        "##STEP 4 // TRY OUR TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQzXfbxlImb"
      },
      "source": [
        "# Let's choose several seeds:\n",
        "string_seed0 = 'alex and max meet at school and discover a'\n",
        "string_seed1 = 'kian goes on a mission to'\n",
        "string_seed2 = 'professor andrew goes on a mission to' \n",
        "string_seed3 = 'alex is pretty rich and famous but she discovers'\n",
        "string_seed4 = 'judy is feeling lonely and'\n",
        "string_seed5 = 'a group of friends decides to go out for'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLbBq4WReXd"
      },
      "source": [
        "# Functions to produce text with our Encoder-Decoder Model\n",
        "\n",
        "every = 5\n",
        "end = tokenizer.texts_to_sequences([['<end>']])[0][0] \n",
        "start = tokenizer.texts_to_sequences([['<start>']])[0][0] \n",
        "dicke = tokenizer.texts_to_sequences([[\"dickens'\"]])[0][0]\n",
        "\n",
        "# Sampling\n",
        "def sample(preds, greedy = False):\n",
        "  # This first function samples the next word based on the output logits from the model\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #print(preds)\n",
        "  preds[0] = np.min(preds) # Minimize prob of <UNK> from being generated as it is not useful\n",
        "  preds[start-1] = np.min(preds) # Minimize prob of <start> from being generated as it is not useful\n",
        "  preds[dicke-1] = np.min(preds) # Minimize prob of \"dicken'\" from being generated as it is not useful\n",
        "  preds = preds-np.max(preds)\n",
        "  preds = np.exp(preds)\n",
        "  preds = preds/np.sum(preds)\n",
        "  samp = np.random.multinomial(1, preds, 1)\n",
        "  if greedy: \n",
        "    out = max(1, np.argmax(preds))\n",
        "  else: \n",
        "    out = np.argmax(samp)\n",
        "  return out+1\n",
        "\n",
        "# Genre Utils\n",
        "listgenre = ['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy','foreign', \n",
        "             'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi','thriller', 'tv_movie', 'war', 'western']\n",
        "dictgenre = {listgenre[i] : i for i in range(len(listgenre))}\n",
        "\n",
        "# Generate Text\n",
        "def model_generate_text(model = modelgen, seed = string_seed1, genre = ['drama'], length = 100, greedy = False, verbose = True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = '<START> '+seed\n",
        "    output = []\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "    genre_in = np.zeros((1,20))\n",
        "    for g in genre:\n",
        "      i = dictgenre[g]\n",
        "      genre_in[:,i] = 1\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    v = 0\n",
        "    while i != end and count <length:     \n",
        "      preds = model.predict([genre_in, x_in], verbose=0)[0]\n",
        "      i = sample(preds, greedy=greedy)\n",
        "      x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "      output.append(i)\n",
        "      count +=1\n",
        "      #v = count/15\n",
        "    if verbose: print(seed+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYsMM6PmdO8w",
        "outputId": "92595329-87f9-42cd-c332-750f084acf0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now let's produce text with our fully trained model: \n",
        "\n",
        "seed1 = string_seed5\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text(model = modelgen, seed = seed1, genre =['romance'], length = 65)\n",
        "text3, output3 = model_generate_text(model = modelgen, seed = seed1, genre =['mystery', 'action'], length = 65)\n",
        "text4, output4 = model_generate_text(model = modelgen, seed = seed1, genre =['thriller', 'crime'], length = 65)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ RANDOM ____________________\n",
            " \n",
            "a group of friends decides to go out for another motorcycle island by his apartment albert starts an adventurous journey to discover his identity . <end>\n",
            "a group of friends decides to go out for another money first after another on the case may have been invaded by a werewolf . when a team of murderous thieves are orphaned . . . . . eric's any kingdom . lucy has just all to know his attention and the most gorgeous professional girl jimmy has not using her and say that she is responsible for caring them for help . after\n",
            "a group of friends decides to go out for dinner . sneak by the drug the local sheriff sam gen . for the town dr . alex jo and molly try to talk about it all . <end>\n",
            " \n",
            "__________________________________________________\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQT8wd2SQzo"
      },
      "source": [
        "## STEP 5 // EVALUATE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un1h23LA5qKv"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "univ_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQLy-5Cq6UOZ"
      },
      "source": [
        "# Generate Text for the evaluation process\n",
        "def eval_generate(seed, genre, length):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = seed\n",
        "    output = []\n",
        "    x_in = pad_sequences(tokenizer.texts_to_sequences([input]), maxlen=10)\n",
        "    genre_in = genre\n",
        "\n",
        "    i = -1\n",
        "    count = 0\n",
        "    v = 0\n",
        "    while count <length:     \n",
        "      preds = modelgen.predict([genre_in, x_in], verbose=0)[0]\n",
        "      i = sample(preds, greedy=True)\n",
        "      x_in = np.append(x_in[:,1:],i).reshape((1,10))\n",
        "      output.append(i)\n",
        "      count +=1\n",
        "    return str(seed+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-osxCTZy_L"
      },
      "source": [
        "# EVALUATE BLEU & COSINE SIMILARITY ON THE TEST SET\n",
        "\n",
        "def cosine_sim(x,y):\n",
        "    num = np.sum(x*y)\n",
        "    den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
        "    return num/float(den)\n",
        "\n",
        "def evaluate_gen(greedy = True):\n",
        "  bleu = []\n",
        "  sim = [] \n",
        "\n",
        "  for j, synopsis in enumerate(testtokens):\n",
        "    #From test set:\n",
        "    input = tokenizer.sequences_to_texts([synopsis[:10]])[0]\n",
        "    output_test = synopsis[10:]\n",
        "    output_test_string = tokenizer.sequences_to_texts([output_test])[0]\n",
        "    output_test_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output_test]\n",
        "    emb_test = univ_embed([output_test_string])\n",
        "    l = len(synopsis)-10\n",
        "\n",
        "\n",
        "    #From model:\n",
        "    _, output = eval_generate(genre = genretest[j,:].reshape(1,20) ,seed = input, length = l)\n",
        "    output_string = tokenizer.sequences_to_texts([output])[0]\n",
        "    output_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output]\n",
        "    emb = univ_embed([output_string])\n",
        "    #Similarity Scores:\n",
        "    b = sentence_bleu([output_test_list], output_list, smoothing_function=SmoothingFunction().method2)\n",
        "    s = cosine_sim(emb, emb_test)\n",
        "\n",
        "    if j%100 == 0: \n",
        "      print(j, \" done!\")\n",
        "      #print(\"bleu: \", b)\n",
        "      #print(\"sim: \", s)\n",
        "\n",
        "    bleu.append(b)\n",
        "    sim.append(s)\n",
        "  \n",
        "  bleu_score = np.mean(bleu)\n",
        "  sim_score = np.mean(sim)\n",
        "  print(\"BLEU: \", bleu_score)\n",
        "  print(\"COS. SIMILARITY: \", sim_score)\n",
        "  return bleu_score, sim_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dakk-DOe7F29",
        "outputId": "9156d62d-9762-484a-858e-ac9c87165bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Encoder-Decoder Performance:\")\n",
        "bleu_score, sim_score = evaluate_gen()\n",
        "\n",
        "print(\"----------- Metrics -----------\")\n",
        "print(\"BLEU: \", np.round(bleu_score,4))\n",
        "print(\"COS. SIMILARITY: \", np.round(sim_score,4))\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder-Decoder Performance:\n",
            "0  done!\n",
            "100  done!\n",
            "200  done!\n",
            "300  done!\n",
            "400  done!\n",
            "BLEU:  0.06268873925101057\n",
            "COS. SIMILARITY:  0.2592567894944022\n",
            "----------- Metrics -----------\n",
            "BLEU:  0.0627\n",
            "COS. SIMILARITY:  0.2593\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}