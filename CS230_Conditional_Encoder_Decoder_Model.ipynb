{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230 // Conditional Encoder-Decoder Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-XuY71GfoOlL",
        "_TBM529kn9pG",
        "mzVUh3ugx4-7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGCCycHnkW2"
      },
      "source": [
        "# Conditional Encoder-Decoder Model\n",
        "\n",
        "\n",
        "*   STEP 1 TOKENIZE THE DATA\n",
        "*   STEP 2 PREPROCESS THE DATA FOR TRAINING\n",
        "*   STEP 3 BUILD & TRAIN THE ENCODER-DECODER MODEL\n",
        "*   STEP 4 LET'S TRY OUR TRAINED MODEL!\n",
        "*   STEP 5 EVALUATE RESULTS (BLEU & UNIVERSAL COSINE SIMILARITY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4k2TbnU5tH",
        "outputId": "46b2cbe7-d79c-4343-8262-5341e38c5556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuY71GfoOlL"
      },
      "source": [
        "## STEP 0 // IMPORT OUR STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxDWxe4VxAu"
      },
      "source": [
        "# !pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from itertools import compress\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zGiy35aw4jb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Masking, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPZWpwlTeF1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "univ_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgJUkSeVz3Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS230/finaldata.csv')\n",
        "train = pd.read_csv('/content/drive/My Drive/CS230/finaldata_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/CS230/finaldata_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8ZuOz2VzcK",
        "outputId": "e9e1ee79-e312-4db9-fd1a-aa7925a67dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.head(5).iloc[:, :10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "      <th>title</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>length</th>\n",
              "      <th>num_genres</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['animation', 'comedy', 'family']</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>7.7</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['adventure', 'fantasy', 'family']</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['romance', 'comedy']</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>6.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['comedy']</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>5.7</td>\n",
              "      <td>173.0</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
              "      <td>Heat</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>55</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     genres  ... animation\n",
              "0         ['animation', 'comedy', 'family']  ...         1\n",
              "1        ['adventure', 'fantasy', 'family']  ...         0\n",
              "2                     ['romance', 'comedy']  ...         0\n",
              "3                                ['comedy']  ...         0\n",
              "4  ['action', 'crime', 'drama', 'thriller']  ...         0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBM529kn9pG"
      },
      "source": [
        "## STEP1 // LET'S TOKENIZE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-RCyHAlIO5O"
      },
      "source": [
        "data['overview_stop']=['<START> '+a+' <END>' for a in data.overview_stop]\n",
        "train['overview_stop']=['<START> '+a+' <END>' for a in train.overview_stop]\n",
        "test['overview_stop']=['<START> '+a+' <END>' for a in test.overview_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhzJv7vfoD1"
      },
      "source": [
        "# Tokenizing / Create a Tokenizer object\n",
        "\n",
        "liststrings = list(data.overview_stop)\n",
        "size_dict = 9000\n",
        "tokenizer = Tokenizer(num_words= size_dict+1, \n",
        "                      filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                      split=' ', \n",
        "                      oov_token='<UNK>',\n",
        "                      document_count=0)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(liststrings) \n",
        "seqtokens = tokenizer.texts_to_sequences(liststrings)\n",
        "traintokens = tokenizer.texts_to_sequences(list(train.overview_stop))\n",
        "testtokens = tokenizer.texts_to_sequences(list(test.overview_stop))\n",
        "\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "dict_counts = tokenizer_config['word_counts']\n",
        "dict_index = tokenizer_config['word_index'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5g55F2yXtw",
        "outputId": "a50b3780-5557-450b-fcfa-70426492d6ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.sequences_to_texts(seqtokens)[:2] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<start> led by woody andy's toys live happily in his room until andy's birthday brings buzz <UNK> onto the scene . afraid of losing his place in andy's heart woody plots against buzz . but when circumstances separate buzz and woody from their owner the duo eventually learns to put aside their differences . <end>\",\n",
              " \"<start> when siblings judy and peter discover an enchanted board game that opens the door to a magical world they unwittingly invite alan an adult who's been trapped inside the game for 26 years into their living room . <UNK> only hope for freedom is to finish the game which proves risky as all three find themselves running from giant <UNK> evil <UNK> and other terrifying creatures . <end>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8q73BterB80"
      },
      "source": [
        "##STEP2 // PREPROCESS THE DATA FOR TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBGL83TyZMtE",
        "outputId": "8286736e-854f-41c1-a310-fede23d77fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### WORD-LEVEL LANGUAGE MODEL WITH SEQ TO SEQ STRUCTURE ###\n",
        "# Script inspired in parts by the CHAR-LEVEL model: lstm_seq2seq.py by fchollet https://github.com/keras-team/keras\n",
        "# Adapted by: ceciloge@stanford.edu\n",
        "\n",
        "# PREPPING THE (INPUT GENRE) ENCODER DATA:\n",
        "\n",
        "genredata = np.array(data[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretrain = np.array(train[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "genretest = np.array(test[['action', 'adventure', 'animation', 'comedy', 'crime', 'documentary', 'drama', 'family', \n",
        "                           'fantasy','foreign', 'history', 'horror', 'music', 'mystery', 'romance', 'sci_fi',\n",
        "                           'thriller', 'tv_movie', 'war', 'western']])\n",
        "\n",
        "m = genretrain.shape[0]\n",
        "num_genres = genretrain.shape[1]\n",
        "print(\"Size of Training Set: \", m) \n",
        "print(\"Max sequence length for input (genres):\", num_genres) #num_encoder_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Training Set:  20277\n",
            "Max sequence length for input (genres): 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbPmn0QNrARc",
        "outputId": "64bea147-eaee-4cce-9ff6-56e2540127b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocess the text into smaller sequences of words on one side (window length), and output next word on the other\n",
        "win_len = 10\n",
        "tokens = traintokens\n",
        "genre_cond = [] #ENCODER\n",
        "x_input = [] #DECODER INPUT\n",
        "y_next = []  #DECODER OUTPUT\n",
        "\n",
        "for j, text in enumerate(tokens):\n",
        "  if j%5000 == 0: print(\"We're at...\", j)\n",
        "  for i in range(len(text)-win_len):\n",
        "    x_input.append(text[i:i+win_len])\n",
        "    y_next.append(text[i+win_len])\n",
        "    genre_cond.append(genretrain[j,:])\n",
        "\n",
        "print(\"Total number of smaller sequences: \", len(x_input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're at... 0\n",
            "We're at... 5000\n",
            "We're at... 10000\n",
            "We're at... 15000\n",
            "We're at... 20000\n",
            "Total number of smaller sequences:  878744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLYhmy3Fr_Gq",
        "outputId": "9d02105e-2d29-4c2e-d37e-88e37aa96e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turning our sequences into arrays\n",
        "x_input_array = np.array([np.array(s) for s in x_input]) #Decoder Input\n",
        "y_next_array = np.array([np.array(s) for s in y_next])-1 #Decoder Output\n",
        "genre_array = np.array(genre_cond) #Encoder Input\n",
        "print('x Shape: ',x_input_array.shape)\n",
        "print('y Shape: ',y_next_array.shape)\n",
        "print('genre Shape: ',genre_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Shape:  (878744, 10)\n",
            "y Shape:  (878744,)\n",
            "genre Shape:  (878744, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhT0ICnio_C0"
      },
      "source": [
        "##STEP 3 // BUILD & TRAIN THE ENCODER-DECODER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9a8aQ6vZ-Vs",
        "outputId": "59bbbb2c-962d-4555-a6e8-4950286ad0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Start with the ENCODER (input is genretrain)\n",
        "encoder_input = Input(shape=(num_genres,))\n",
        "encoder = Dense(256)(encoder_input)\n",
        "# The state will then be used as input for the decoder\n",
        "\n",
        "\n",
        "# Input & Embedding for DECODER \n",
        "decoder_input = Input(shape=(win_len,))\n",
        "h = Embedding(size_dict+1, 64, input_length = win_len, mask_zero=True, name = 'embedding')(decoder_input)\n",
        "\n",
        "# Three GRU Layers\n",
        "h = GRU(256, name = 'GRU1', return_sequences= True)(h, initial_state=encoder)\n",
        "h = GRU(256, name = 'GRU2', return_sequences= True)(h)\n",
        "h = GRU(256, name = 'GRU3')(h)\n",
        "\n",
        "# Final Dense Layers\n",
        "h = Dense(512, activation = 'relu', name = 'dense1')(h)\n",
        "h = Dense(2560, activation = 'relu', name = 'dense2')(h)\n",
        "next_word = Dense(size_dict, activation='linear', name = 'final')(h)\n",
        "\n",
        "# The model to train:\n",
        "modelgen = Model([encoder_input, decoder_input], next_word)\n",
        "modelgen.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 10, 64)       576064      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          5376        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "GRU1 (GRU)                      (None, 10, 256)      247296      embedding[0][0]                  \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "GRU2 (GRU)                      (None, 10, 256)      394752      GRU1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "GRU3 (GRU)                      (None, 256)          394752      GRU2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          131584      GRU3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 2560)         1313280     dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "final (Dense)                   (None, 9000)         23049000    dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 26,112,104\n",
            "Trainable params: 26,112,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0QgjEyu67II",
        "outputId": "329458c4-3c1b-4761-ddbf-bae9d8564d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = Adamax(learning_rate=0.01)\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True, name='sparse_cce')\n",
        "modelgen.compile(loss=loss, optimizer=opt)\n",
        "print('Ready!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QhvuK617Xah",
        "outputId": "d818bc62-1963-4021-917d-828f0df2ad89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelgen.load_weights('/content/drive/My Drive/CS230/Models/encoder2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff66726ac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8rJoBkGlYlH",
        "outputId": "fb0d3d44-66f1-402f-c8e6-5ed06515469b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelgen.fit([genre_array, x_input_array], y_next_array,\n",
        "             batch_size = 256,\n",
        "             epochs = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0595\n",
            "Epoch 2/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0572\n",
            "Epoch 3/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0577\n",
            "Epoch 4/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0517\n",
            "Epoch 5/30\n",
            "3433/3433 [==============================] - 90s 26ms/step - loss: 6.0461\n",
            "Epoch 6/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0487\n",
            "Epoch 7/30\n",
            "3433/3433 [==============================] - 90s 26ms/step - loss: 6.0515\n",
            "Epoch 8/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0500\n",
            "Epoch 9/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0455\n",
            "Epoch 10/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0434\n",
            "Epoch 11/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0447\n",
            "Epoch 12/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0420\n",
            "Epoch 13/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0396\n",
            "Epoch 14/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0388\n",
            "Epoch 15/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0400\n",
            "Epoch 16/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0396\n",
            "Epoch 17/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0402\n",
            "Epoch 18/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0377\n",
            "Epoch 19/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0368\n",
            "Epoch 20/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0349\n",
            "Epoch 21/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0335\n",
            "Epoch 22/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0345\n",
            "Epoch 23/30\n",
            "3433/3433 [==============================] - 89s 26ms/step - loss: 6.0338\n",
            "Epoch 24/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0359\n",
            "Epoch 25/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0397\n",
            "Epoch 26/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0393\n",
            "Epoch 27/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0386\n",
            "Epoch 28/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0357\n",
            "Epoch 29/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0368\n",
            "Epoch 30/30\n",
            "3433/3433 [==============================] - 88s 26ms/step - loss: 6.0358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff6671ba518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10tbYWMn7Kqs"
      },
      "source": [
        "modelgen.save_weights('/content/drive/My Drive/CS230/Models/encoder2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLbBq4WReXd"
      },
      "source": [
        "# Functions to produce text\n",
        "\n",
        "every = 5\n",
        "\n",
        "def generate_text2(epoch, _):\n",
        "  # This second function prints generated text at end of every few epochs\n",
        "  if epoch%every == 0:\n",
        "    print()\n",
        "    input = 'when siblings judy and peter discover a board game that'\n",
        "    print('Seed: \"' + input + '\"')\n",
        "    output = []\n",
        "    x_in = np.array(tokenizer.texts_to_sequences([input])[0])\n",
        "    for i in range(60):     \n",
        "      preds = gen_model2.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      next_idx = sample(preds)\n",
        "      x_in = np.append(x_in[1:],next_idx)\n",
        "      output.append(next_idx)\n",
        "    print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "\n",
        "\n",
        "# Defining our callbacks - reusing code from previous model:\n",
        "checkpoint2 = ModelCheckpoint(filepath='model2',\n",
        "                             frequency = \"epoch\",\n",
        "                             save_weights_only = True,\n",
        "                             verbose = 0)\n",
        "\n",
        "gen_callback2 = LambdaCallback(on_epoch_end=generate_text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQzXfbxlImb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yijSQP5Yec7"
      },
      "source": [
        "##STEP 4 // TRY OUR TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQYkSW8bdKrf"
      },
      "source": [
        "# Let's choose several seeds:\n",
        "\n",
        "string_seed0 = 'when siblings judy and peter discover a board game that'\n",
        "string_seed1 = 'andy and judy met a year ago for the first'\n",
        "string_seed2 = 'alex is willing to accept a new mission to save' \n",
        "string_seed3 = 'led by alex the gang decides to take on a'\n",
        "string_seed4 = 'judy is a young woman who is starting to feel'\n",
        "string_seed5 = 'a group of friends decide to go out for a'\n",
        "string_seed6 = '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
        "\n",
        "def model_generate_text2(model, seed = string_seed1, length = 100, greedy = False, verbose = True):\n",
        "    # This function generates text from a given seed - works like the callback function.\n",
        "    input = seed\n",
        "    output = []\n",
        "    x_in = tokenizer.texts_to_sequences([input])\n",
        "    x_in = np.array(x_in[0])\n",
        "\n",
        "    for i in range(length):     \n",
        "      preds = model.predict(x_in.reshape((1,x_in.shape[0])), verbose=0)[0]\n",
        "      next_idx = sample(preds, greedy = greedy)\n",
        "      x_in = np.append(x_in[1:],next_idx)\n",
        "      output.append(next_idx)\n",
        "    if verbose: print(input+\" \"+tokenizer.sequences_to_texts([output])[0])\n",
        "    return str(input+\" \"+tokenizer.sequences_to_texts([output])[0]), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYsMM6PmdO8w"
      },
      "source": [
        "# Now let's produce text with our fully trained model: \n",
        "\n",
        "text0, output0 = model_generate_text2(model = gen_model2, seed = string_seed0, length = 65, greedy = True)\n",
        "text0, output0 = model_generate_text2(model = gen_model2, seed = string_seed0, length = 65, greedy = False)\n",
        "print(20*\"_\"+\" RANDOM \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text1, output1 = model_generate_text2(model = gen_model2, seed = string_seed1, length = 65)\n",
        "text2, output2 = model_generate_text2(model = gen_model2, seed = string_seed2, length = 65)\n",
        "text3, output3 = model_generate_text2(model = gen_model2, seed = string_seed3, length = 65)\n",
        "text4, output4 = model_generate_text2(model = gen_model2, seed = string_seed4, length = 65)\n",
        "text5, output5 = model_generate_text2(model = gen_model2, seed = string_seed5, length = 65)\n",
        "print(\" \")\n",
        "print(50*\"_\")\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" GREEDY \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text6, output6 = model_generate_text2(model = gen_model2, seed = string_seed1, length = 65, greedy = True)\n",
        "text7, output7 = model_generate_text2(model = gen_model2, seed = string_seed2, length = 65, greedy = True)\n",
        "text8, output8 = model_generate_text2(model = gen_model2, seed = string_seed3, length = 65, greedy = True)\n",
        "text9, output9 = model_generate_text2(model = gen_model2, seed = string_seed4, length = 65, greedy = True)\n",
        "text10, output10 = model_generate_text2(model = gen_model2, seed = string_seed5, length = 65, greedy = True)\n",
        "print(\" \")\n",
        "print(20*\"_\"+\" NO REAL SEED \" + 20*\"_\")\n",
        "print(\" \")\n",
        "text11, output11 = model_generate_text2(model = gen_model2, seed = string_seed6, length = 65, greedy = False)\n",
        "text11, output11 = model_generate_text2(model = gen_model2, seed = string_seed6, length = 65, greedy = False)\n",
        "print(\" \")\n",
        "print(50*\"_\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQT8wd2SQzo"
      },
      "source": [
        "## STEP 5 // EVALUATE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-osxCTZy_L"
      },
      "source": [
        "# EVALUATE BLEU & COSINE SIMILARITY ON THE TEST SET\n",
        "\n",
        "def cosine_sim(x,y):\n",
        "    num = np.sum(x*y)\n",
        "    den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
        "    return num/float(den)\n",
        "\n",
        "def evaluate_gen(version, greedy = True):\n",
        "  bleu = []\n",
        "  sim = []\n",
        "  if version == 1: \n",
        "    model = gen_model\n",
        "    fun = model_generate_text\n",
        "  else:\n",
        "    model = gen_model2\n",
        "    fun = model_generate_text2   \n",
        "  \n",
        "  for j, synopsis in enumerate(testtokens[:250]):\n",
        "    #From test set:\n",
        "    input = tokenizer.sequences_to_texts([synopsis[:10]])[0]\n",
        "    output_test = synopsis[10:]\n",
        "    output_test_string = tokenizer.sequences_to_texts([output_test])[0]\n",
        "    output_test_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output_test]\n",
        "    emb_test = univ_embed([output_test_string])\n",
        "    l = len(synopsis)-10\n",
        "\n",
        "\n",
        "    #From model:\n",
        "    _, output = fun(model = model, seed = input, length = l, greedy = greedy, verbose = False)\n",
        "    output_string = tokenizer.sequences_to_texts([output])[0]\n",
        "    output_list = [tokenizer.sequences_to_texts([[i]])[0] for i in output]\n",
        "    emb = univ_embed([output_string])\n",
        "    #Similarity Scores:\n",
        "    b = sentence_bleu([output_test_list], output_list, smoothing_function=SmoothingFunction().method2)\n",
        "    s = cosine_sim(emb, emb_test)\n",
        "\n",
        "    if j%20 == 0: \n",
        "      print(j, \" done!\")\n",
        "      #print(\"bleu: \", b)\n",
        "      #print(\"sim: \", s)\n",
        "\n",
        "    bleu.append(b)\n",
        "    sim.append(s)\n",
        "  \n",
        "  bleu_score = np.mean(bleu)\n",
        "  sim_score = np.mean(sim)\n",
        "  print(\"BLEU: \", bleu_score)\n",
        "  print(\"COS. SIMILARITY: \", sim_score)\n",
        "  return bleu_score, sim_score"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}